{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257733a8-bed5-4705-b130-d558d2daa494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright  2024 Forusone\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cf3630-0a84-4782-9467-3c46ef958a4b",
   "metadata": {},
   "source": [
    "## Torch in Ray Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e8f6c44-6bcf-42eb-b82a-1cca6de6d459",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2022 NVIDIA Corporation\n",
      "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
      "Cuda compilation tools, release 11.8, V11.8.89\n",
      "Build cuda_11.8.r11.8/compiler.31833905_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d11c1de-2b7a-48df-974d-7824ae3f49eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Feb 17 00:58:32 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA L4                      On  |   00000000:00:03.0 Off |                    0 |\n",
      "| N/A   76C    P0             34W /   72W |     301MiB /  23034MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA L4                      On  |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   47C    P8             17W /   72W |       4MiB /  23034MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   2  NVIDIA L4                      On  |   00000000:00:05.0 Off |                    0 |\n",
      "| N/A   47C    P8             17W /   72W |       4MiB /  23034MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   3  NVIDIA L4                      On  |   00000000:00:06.0 Off |                    0 |\n",
      "| N/A   47C    P8             17W /   72W |       4MiB /  23034MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A   2315223      C   python                                        292MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbeed944-2ede-494d-8663-5a035c32344a",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b4d7ea5-b335-4c2f-a81c-3fb5f838ca03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install --user -q \"google-cloud-aiplatform[ray]>=1.56.0\" \\\n",
    "                        \"ray[data,train,tune,serve]>=2.9.3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61340a12-d9f2-489e-bbd2-d1da3bd5300c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.9.3', '2.1.4')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ray\n",
    "import ray.train.torch\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# __torch_setup_begin__\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "ray.__version__, pd.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a733566-e1ab-4cbd-a71e-225c1b099670",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_dataset():\n",
    "    return datasets.FashionMNIST(\n",
    "        root=\"/tmp/data\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=ToTensor(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb8ff86e-6281-4db5-96b4-82dc3ff8a946",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        inputs = self.flatten(inputs)\n",
    "        logits = self.linear_relu_stack(inputs)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36443564-1351-42ea-a4e4-08e070d6c400",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# __torch_single_begin__\n",
    "def train_func():\n",
    "    num_epochs = 3\n",
    "    batch_size = 64\n",
    "\n",
    "    dataset = get_dataset()\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "    model = NeuralNetwork()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for inputs, labels in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(inputs)\n",
    "            loss = criterion(pred, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"epoch: {epoch}, loss: {loss.item()}\")\n",
    "# __torch_single_end__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a9b46df-201f-49d6-8dc7-b4f4e590b314",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# __torch_distributed_begin__\n",
    "import ray.train.torch\n",
    "\n",
    "def train_func_distributed():\n",
    "    num_epochs = 4\n",
    "    batch_size = 64\n",
    "\n",
    "    dataset = get_dataset()\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    dataloader = ray.train.torch.prepare_data_loader(dataloader)\n",
    "\n",
    "    model = NeuralNetwork()\n",
    "    model = ray.train.torch.prepare_model(model)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        if ray.train.get_context().get_world_size() > 1:\n",
    "            dataloader.sampler.set_epoch(epoch)\n",
    "\n",
    "        for inputs, labels in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(inputs)\n",
    "            loss = criterion(pred, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"epoch: {epoch}, loss: {loss.item()}\")\n",
    "# __torch_distributed_end__\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "535f2cdc-e6d8-423e-b008-9910cb5f8aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2025-02-17 01:15:00</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:24.72        </td></tr>\n",
       "<tr><td>Memory:      </td><td>24.3/188.7 GiB     </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 5.0/48 CPUs, 0/4 GPUs (0.0/1.0 accelerator_type:L4)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>status    </th><th>loc              </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TorchTrainer_8d095_00000</td><td>TERMINATED</td><td>10.128.0.4:133117</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-17 01:14:35,579\tINFO data_parallel_trainer.py:344 -- GPUs are detected in your Ray cluster, but GPU training is not enabled for this trainer. To enable GPU training, make sure to set `use_gpu` to True in your scaling config.\n",
      "\u001b[36m(TrainTrainable pid=133117)\u001b[0m GPUs are detected in your Ray cluster, but GPU training is not enabled for this trainer. To enable GPU training, make sure to set `use_gpu` to True in your scaling config.\n",
      "\u001b[36m(TorchTrainer pid=133117)\u001b[0m GPUs are detected in your Ray cluster, but GPU training is not enabled for this trainer. To enable GPU training, make sure to set `use_gpu` to True in your scaling config.\n",
      "\u001b[36m(RayTrainWorker pid=133965)\u001b[0m Setting up process group for: env:// [rank=0, world_size=4]\n",
      "\u001b[36m(TorchTrainer pid=133117)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(TorchTrainer pid=133117)\u001b[0m - (ip=10.128.0.4, pid=133965) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(TorchTrainer pid=133117)\u001b[0m - (ip=10.128.0.4, pid=133966) world_rank=1, local_rank=1, node_rank=0\n",
      "\u001b[36m(TorchTrainer pid=133117)\u001b[0m - (ip=10.128.0.4, pid=133967) world_rank=2, local_rank=2, node_rank=0\n",
      "\u001b[36m(TorchTrainer pid=133117)\u001b[0m - (ip=10.128.0.4, pid=133968) world_rank=3, local_rank=3, node_rank=0\n",
      "\u001b[36m(RayTrainWorker pid=133965)\u001b[0m Moving model to device: cpu\n",
      "\u001b[36m(RayTrainWorker pid=133965)\u001b[0m Wrapping provided model in DistributedDataParallel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=133968)\u001b[0m epoch: 0, loss: 1.6010398864746094\n",
      "\u001b[36m(RayTrainWorker pid=133968)\u001b[0m epoch: 2, loss: 0.7470226287841797\u001b[32m [repeated 8x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "Trial TorchTrainer_8d095_00000 completed. Last result: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-17 01:15:00,296\tINFO tune.py:1042 -- Total run time: 24.76 seconds (24.72 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- end training ---\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # __torch_single_run_begin__\n",
    "    train_func()\n",
    "    # __torch_single_run_end__\n",
    "\n",
    "    # __torch_trainer_begin__\n",
    "    from ray.train.torch import TorchTrainer\n",
    "    from ray.train import ScalingConfig\n",
    "\n",
    "    # For GPU Training, set `use_gpu` to True.\n",
    "    use_gpu = False\n",
    "\n",
    "    trainer = TorchTrainer(\n",
    "        train_func_distributed,\n",
    "        scaling_config=ScalingConfig(num_workers=4, use_gpu=use_gpu)\n",
    "    )\n",
    "\n",
    "    results = trainer.fit()\n",
    "    \n",
    "    print(\"---- end training ---\")\n",
    "    \n",
    "    # __torch_trainer_end__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd9d827-8233-4e3f-8a31-089c8222106d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m127",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m127"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
