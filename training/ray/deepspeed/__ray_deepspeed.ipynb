{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68aa20b8-3d41-4b13-a084-ab5343c29953",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e9d538-7216-43b3-973f-eea47b101c2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bda7933-199b-46f5-ada9-21f961bb0fb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ray\n",
    "\n",
    "service_host = os.environ[\"RAY_HEAD_SERVICE_HOST\"]\n",
    "service_port = os.environ[\"RAY_HEAD_SERVICE_PORT\"]\n",
    "\n",
    "runtime_env = {\"RAY_DATA_STRICT_MODE\": \"0\"}\n",
    "\n",
    "\n",
    "if ray.is_initialized() == False:\n",
    "   ray.init(f\"ray://{service_host}:{service_port}\",\n",
    "            log_to_driver=True,\n",
    "            ignore_reinit_error=True,\n",
    "            # runtime_env=runtime_env,\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85766dcb-3cb5-449c-92aa-1b44b8b96e74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"EleutherAI/gpt-j-6B\"\n",
    "use_gpu = True\n",
    "num_workers = 32\n",
    "cpus_per_worker = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa94622-fbfd-40ff-abb8-1cd56fb79e91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset, DatasetDict, load_from_disk\n",
    "\n",
    "print(\"Loading Newton dataset\")\n",
    "current_dataset = load_from_disk('/mnt/Newton_Principles.hf/')\n",
    "# Uncomment below to load the dataset from the huggingface hub\n",
    "# current_dataset = load_dataset(\"asheinin/The_Mathematical_Principles_of_Natural_Philosophy_1846\")\n",
    "current_dataset =  DatasetDict({'train': Dataset.from_dict({'text': ['\\n'.join(current_dataset['train']['text'])]})})\n",
    "current_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9c0593-dfcd-49d7-afaf-aebf6399e145",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ray.data\n",
    "\n",
    "ray_datasets = ray.data.from_huggingface(current_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605d1dc4-948d-48d5-9222-229c59ddc9e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "block_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ee51d6-42da-4afd-83c7-e40e72ad22e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "from ray.data.preprocessors import BatchMapper\n",
    "\n",
    "\n",
    "def split_text(batch: pd.DataFrame) -> pd.DataFrame:\n",
    "    text = list(batch[\"text\"])\n",
    "    flat_text = \"\".join(text)\n",
    "    split_text = [\n",
    "        x.strip()\n",
    "        for x in flat_text.split(\"\\n\")\n",
    "        if x.strip() and not x.strip()[-1] == \":\"\n",
    "    ]\n",
    "    return pd.DataFrame(split_text, columns=[\"text\"])\n",
    "\n",
    "\n",
    "def tokenize(batch: pd.DataFrame) -> dict:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    ret = tokenizer(\n",
    "        list(batch[\"text\"]),\n",
    "        truncation=True,\n",
    "        max_length=block_size,\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=\"np\",\n",
    "    )\n",
    "    ret[\"labels\"] = ret[\"input_ids\"].copy()\n",
    "    return dict(ret)\n",
    "\n",
    "\n",
    "splitter = BatchMapper(split_text, batch_format=\"pandas\")\n",
    "tokenizer = BatchMapper(tokenize, batch_format=\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95ef3a8-adaa-4bb3-8655-f15c5f6e85f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import (\n",
    "    GPTJForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    default_data_collator,\n",
    ")\n",
    "from transformers.utils.logging import disable_progress_bar, enable_progress_bar\n",
    "import torch\n",
    "\n",
    "from ray.air import session\n",
    "\n",
    "\n",
    "def trainer_init_per_worker(train_dataset, eval_dataset=None, **config):\n",
    "    # Use the actual number of CPUs assigned by Ray\n",
    "    os.environ[\"OMP_NUM_THREADS\"] = str(\n",
    "        session.get_trial_resources().bundles[-1].get(\"CPU\", 1)\n",
    "    )\n",
    "    # Enable tf32 for better performance\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "    batch_size = config.get(\"batch_size\", 4)\n",
    "    epochs = config.get(\"epochs\", 2)\n",
    "    warmup_steps = config.get(\"warmup_steps\", 0)\n",
    "    learning_rate = config.get(\"learning_rate\", 0.00002)\n",
    "    weight_decay = config.get(\"weight_decay\", 0.01)\n",
    "\n",
    "    deepspeed = {\n",
    "        \"fp16\": {\n",
    "            \"enabled\": \"auto\",\n",
    "            \"initial_scale_power\": 8,\n",
    "        },\n",
    "        \"bf16\": {\"enabled\": \"auto\"},\n",
    "        \"optimizer\": {\n",
    "            \"type\": \"AdamW\",\n",
    "            \"params\": {\n",
    "                \"lr\": \"auto\",\n",
    "                \"betas\": \"auto\",\n",
    "                \"eps\": \"auto\",\n",
    "            },\n",
    "        },\n",
    "        \"zero_optimization\": {\n",
    "            \"stage\": 3,\n",
    "            \"offload_optimizer\": {\n",
    "                \"device\": \"cpu\",\n",
    "                \"pin_memory\": True,\n",
    "            },\n",
    "            \"overlap_comm\": False,\n",
    "            \"contiguous_gradients\": True,\n",
    "            \"reduce_bucket_size\": \"auto\",\n",
    "            \"stage3_prefetch_bucket_size\": \"auto\",\n",
    "            \"stage3_param_persistence_threshold\": \"auto\",\n",
    "            \"gather_16bit_weights_on_model_save\": True,\n",
    "            \"round_robin_gradients\": True,\n",
    "        },\n",
    "        \"gradient_accumulation_steps\": \"auto\",\n",
    "        \"gradient_clipping\": \"auto\",\n",
    "        \"steps_per_print\": 10,\n",
    "        \"train_batch_size\": \"auto\",\n",
    "        \"train_micro_batch_size_per_gpu\": \"auto\",\n",
    "        \"wall_clock_breakdown\": False,\n",
    "    }\n",
    "\n",
    "    print(\"Preparing training arguments\")\n",
    "    training_args = TrainingArguments(\n",
    "        \"output\",\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        logging_steps=1,\n",
    "        save_strategy=\"no\",\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        warmup_steps=warmup_steps,\n",
    "        label_names=[\"input_ids\", \"attention_mask\"],\n",
    "        num_train_epochs=epochs,\n",
    "        push_to_hub=False,\n",
    "        disable_tqdm=True,  # declutter the output a little\n",
    "        fp16=True,\n",
    "        gradient_checkpointing=True,\n",
    "        deepspeed=deepspeed,\n",
    "    )\n",
    "    disable_progress_bar()\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    print(\"Loading model\")\n",
    "\n",
    "    model = GPTJForCausalLM.from_pretrained(model_name, use_cache=False)\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "    print(\"Model loaded\")\n",
    "\n",
    "    enable_progress_bar()\n",
    "\n",
    "    metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "    def compute_metrics(eval_pred):\n",
    "        logits, labels = eval_pred\n",
    "        predictions = np.argmax(logits, axis=-1)\n",
    "        return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=default_data_collator,\n",
    "    )\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fb4ed1-6d2a-4e28-aec2-3a4bab1fc147",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "storage_path=\"/domino/datasets/local/Ray_Deepspeed_GPTJ/\"     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69118f9-2b3a-4c3c-9eef-d89e4ed25690",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ray.train.huggingface import TransformersTrainer\n",
    "from ray.air.config import ScalingConfig, RunConfig\n",
    "from ray.data.preprocessors import Chain\n",
    "\n",
    "\n",
    "trainer = TransformersTrainer(\n",
    "    trainer_init_per_worker=trainer_init_per_worker,\n",
    "    trainer_init_config={\n",
    "        \"batch_size\": 4,  # per device\n",
    "        \"epochs\": 1,\n",
    "    },\n",
    "    scaling_config=ScalingConfig(\n",
    "        num_workers=num_workers,\n",
    "        use_gpu=use_gpu,\n",
    "        resources_per_worker={\"GPU\": 1, \"CPU\": cpus_per_worker},\n",
    "    ),\n",
    "    datasets={\"train\": ray_datasets[\"train\"]},# , \"evaluation\": ray_datasets[\"validation\"]},\n",
    "    preprocessor=Chain(splitter, tokenizer),\n",
    "    run_config=RunConfig(storage_path=storage_path),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455df0c9-742d-405a-b9f5-2687a87dcc24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ad1682-3a18-4eb3-b26c-5814e55bca24",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = results.checkpoint\n",
    "checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8065532b-9410-4bb5-8ff3-9d9c8cf79f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint.set_preprocessor(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abd605d-da66-468b-95e2-57ec96aa09ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate some predictions\n",
    "from ray.train.huggingface import TransformersPredictor\n",
    "import pandas as pd\n",
    "\n",
    "prompts = pd.DataFrame([\"Romeo and Juliet\", \"Romeo\", \"Juliet\"], columns=[\"text\"])\n",
    "\n",
    "# Predict on the head node.\n",
    "predictor = TransformersPredictor.from_checkpoint(\n",
    "    checkpoint=checkpoint,\n",
    "    task=\"text-generation\",\n",
    "    torch_dtype=torch.float16 if use_gpu else None,\n",
    "    device_map=\"auto\",\n",
    "    use_gpu=use_gpu,\n",
    ")\n",
    "prediction = predictor.predict(\n",
    "    prompts,\n",
    "    do_sample=True,\n",
    "    temperature=0.9,\n",
    "    min_length=32,\n",
    "    max_length=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a3053f-0f3d-4d99-982d-af570b74c5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m127",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m127"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
