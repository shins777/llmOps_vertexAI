{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UUTFwSh5u9OK"
   },
   "outputs": [],
   "source": [
    "# Copyright 2024 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qsLff0QbdE8D"
   },
   "source": [
    "## Online Prediction PSC based private endpint\n",
    "\n",
    "* [PSC on Vertex AI](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/prediction/get_started_with_psc_private_endpoint.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RakMIliNYh8O"
   },
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "nSHmJT9cTggu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/jupyter/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/jupyter/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/jupyter/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/jupyter/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/jupyter/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/jupyter/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip3 install --upgrade --user --quiet google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HId-ySlY2jlI"
   },
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Y4gnZI9OX6VJ"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"ai-hangsik\"  # @param {type:\"string\"}\n",
    "LOCATION = \"us-central1\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "moS794OKaaCt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://20250211_psc_endpoint/...\n",
      "ServiceException: 409 A Cloud Storage bucket named '20250211_psc_endpoint' already exists. Try another name. Bucket names must be globally unique across all Google Cloud projects, including those outside of your organization.\n"
     ]
    }
   ],
   "source": [
    "# Create GCS Bucket\n",
    "BUCKET_URI = \"gs://20250211_psc_endpoint\"  # @param {type:\"string\"}\n",
    "! gsutil mb -l {LOCATION} -p {PROJECT_ID} {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using this default Service Account: 721521243942-compute@developer.gserviceaccount.com\n"
     ]
    }
   ],
   "source": [
    "# @title Gets the default SERVICE_ACCOUNT.\n",
    "shell_output = ! gcloud projects describe $PROJECT_ID\n",
    "project_number = shell_output[-1].split(\":\")[1].strip().replace(\"'\", \"\")\n",
    "SERVICE_ACCOUNT = f\"{project_number}-compute@developer.gserviceaccount.com\"\n",
    "print(\"Using this default Service Account:\", SERVICE_ACCOUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "swERjzZ-a_Nd"
   },
   "source": [
    "### Upload and deploy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Set accelerator.\n",
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "# Find Vertex AI prediction supported accelerators and regions [here](https://cloud.google.com/vertex-ai/docs/predictions/configure-compute).\n",
    "MACHINE_TYPE = \"g2-standard-12\" # @param {type:\"string\"}\n",
    "ACCELERATOR_TYPE = \"NVIDIA_L4\" # @param {type:\"string\"}\n",
    "ACCELERATOR_COUNT = 1 # @param {type:\"string\"}\n",
    "\n",
    "MODEL_BUCKET_URI =\"gs://sllm_0106/llama3.1_8b_inst\" # @param {type:\"string\"}\n",
    "VLLM_DOCKER_URI = \"us-docker.pkg.dev/deeplearning-platform-release/vertex-model-garden/vllm-inference.cu121.0-5.ubuntu2204.py310\" # @param {type:\"string\"}\n",
    "\n",
    "MODEL_ID = \"vLLM-Meta-Llama-3.1-8B-Instruct\" # @param {type:\"string\"}\n",
    "MODEL_DISPLAY_NAME = f\"{MODEL_ID}-{now}\"\n",
    "ENDPOINT_PSC_NAME = f\"{MODEL_ID}-psc-endpoint-{now}\" # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "# See https://docs.vllm.ai/en/latest/serving/engine_args.html\n",
    "\n",
    "vllm_args = [\n",
    "    \"python\",\n",
    "    \"-m\",\n",
    "    \"vllm.entrypoints.api_server\",\n",
    "    \"--host=0.0.0.0\",\n",
    "    \"--port=8080\",\n",
    "    f\"--model={MODEL_ID}\",\n",
    "    f\"--tensor-parallel-size={ACCELERATOR_COUNT}\",\n",
    "    \"--swap-space=16\",\n",
    "    f\"--gpu-memory-utilization=0.95\",\n",
    "    f\"--max-model-len=8192\",\n",
    "    f\"--dtype=auto\",\n",
    "    f\"--max-loras=1\",\n",
    "    f\"--max-cpu-loras=8\",\n",
    "    f\"--max-num-seqs=256\",\n",
    "    \"--disable-log-stats\",\n",
    "#     \"--trust-remote-code\",\n",
    "#     \"--enforce-eager\",\n",
    "#     \"--enable-lora\",\n",
    "#     \"--model-type=llama\",\n",
    " ]\n",
    "\n",
    "env_vars = {\n",
    "    \"MODEL_ID\": MODEL_ID,\n",
    "    \"DEPLOY_SOURCE\": \"notebook\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model\n",
      "Create Model backing LRO: projects/721521243942/locations/us-central1/models/2705762876026519552/operations/1570212452547690496\n",
      "Model created. Resource name: projects/721521243942/locations/us-central1/models/2705762876026519552@1\n",
      "To use this Model in another session:\n",
      "model = aiplatform.Model('projects/721521243942/locations/us-central1/models/2705762876026519552@1')\n",
      "Deploying vLLM-Meta-Llama-3.1-8B-Instruct-2025-02-11 01:26:32.513605 on g2-standard-12 with 1 NVIDIA_L4 GPU(s).\n"
     ]
    }
   ],
   "source": [
    "# @title Model upload\n",
    "# https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.Model#google_cloud_aiplatform_Model_upload\n",
    "\n",
    "model = aiplatform.Model.upload(\n",
    "    display_name=MODEL_DISPLAY_NAME,\n",
    "    artifact_uri=MODEL_BUCKET_URI,\n",
    "    serving_container_image_uri=VLLM_DOCKER_URI,\n",
    "    serving_container_args=vllm_args,\n",
    "    serving_container_ports=[8080],\n",
    "    # serving_container_predict_route=\"/generate\",\n",
    "    serving_container_predict_route=\"/v1/chat/completions\",\n",
    "    serving_container_health_route=\"/metrics\",\n",
    "    serving_container_environment_variables=env_vars,\n",
    "    serving_container_shared_memory_size_mb=(16 * 1024),  # 16 GB\n",
    "    serving_container_deployment_timeout=7200,\n",
    ")\n",
    "print(\n",
    "    f\"Deploying {MODEL_DISPLAY_NAME} on {MACHINE_TYPE} with {ACCELERATOR_COUNT} {ACCELERATOR_TYPE} GPU(s).\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PrivateEndpoint\n",
      "Create PrivateEndpoint backing LRO: projects/721521243942/locations/us-central1/endpoints/7111316852524974080/operations/1209924482358050816\n",
      "PrivateEndpoint created. Resource name: projects/721521243942/locations/us-central1/endpoints/7111316852524974080\n",
      "To use this PrivateEndpoint in another session:\n",
      "endpoint = aiplatform.PrivateEndpoint('projects/721521243942/locations/us-central1/endpoints/7111316852524974080')\n"
     ]
    }
   ],
   "source": [
    "psc_endpoint = aiplatform.PrivateEndpoint.create(\n",
    "    display_name=ENDPOINT_PSC_NAME,\n",
    "    project=PROJECT_ID,\n",
    "    location=LOCATION,\n",
    "    private_service_connect_config=aiplatform.PrivateEndpoint.PrivateServiceConnectConfig(\n",
    "        project_allowlist=[PROJECT_ID],\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# endpoint = aiplatform.Endpoint.create(\n",
    "#         display_name = ENDPOINT_DISPLAY_NAME,\n",
    "#         dedicated_endpoint_enabled=False,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.deploy(\n",
    "    endpoint=psc_endpoint,\n",
    "    machine_type=MACHINE_TYPE,\n",
    "    accelerator_type=ACCELERATOR_TYPE,\n",
    "    accelerator_count=ACCELERATOR_COUNT,\n",
    "    deploy_request_timeout=1800,\n",
    "    service_account=SERVICE_ACCOUNT,\n",
    ")\n",
    "print(\"endpoint_name:\", psc_endpoint.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "endpoint_name: 7111316852524974080\n"
     ]
    }
   ],
   "source": [
    "print(\"endpoint_name:\", psc_endpoint.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[id: \"1439969905758699520\"\n",
       " model: \"projects/721521243942/locations/us-central1/models/2705762876026519552\"\n",
       " display_name: \"vLLM-Meta-Llama-3.1-8B-Instruct-2025-02-11 01:26:32.513605\"\n",
       " create_time {\n",
       "   seconds: 1739237451\n",
       "   nanos: 149682000\n",
       " }\n",
       " dedicated_resources {\n",
       "   machine_spec {\n",
       "     machine_type: \"g2-standard-12\"\n",
       "     accelerator_type: NVIDIA_L4\n",
       "     accelerator_count: 1\n",
       "   }\n",
       "   min_replica_count: 1\n",
       "   max_replica_count: 1\n",
       " }\n",
       " service_account: \"721521243942-compute@developer.gserviceaccount.com\"\n",
       " private_endpoints {\n",
       "   service_attachment: \"projects/p9573c9b9f79e4e12-tp/regions/us-central1/serviceAttachments/gkedpm-857e734e4abcae27fc309cb9fa21bc\"\n",
       " }\n",
       " model_version_id: \"1\"\n",
       " status {\n",
       "   available_replica_count: 1\n",
       " }]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psc_endpoint.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projects/p9573c9b9f79e4e12-tp/regions/us-central1/serviceAttachments/gkedpm-857e734e4abcae27fc309cb9fa21bc\n"
     ]
    }
   ],
   "source": [
    "service_attachment = psc_endpoint.list_models()[0].private_endpoints.service_attachment\n",
    "print(service_attachment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! gcloud compute forwarding-rules delete  op-psc-llm-endpoint\n",
    "#! gcloud compute addresses delete psc-llm-prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created [https://www.googleapis.com/compute/v1/projects/ai-hangsik/regions/us-central1/addresses/psc-llm-prediction].\n",
      "Created [https://www.googleapis.com/compute/v1/projects/ai-hangsik/regions/us-central1/forwardingRules/op-psc-llm-endpoint].\n"
     ]
    }
   ],
   "source": [
    "! gcloud compute addresses create psc-llm-prediction \\\n",
    "    --region={LOCATION} \\\n",
    "    --subnet=default2\n",
    "\n",
    "! gcloud compute forwarding-rules create op-psc-llm-endpoint \\\n",
    "    --network=default2 \\\n",
    "    --address=psc-llm-prediction \\\n",
    "    --target-service-attachment={service_attachment} \\\n",
    "    --region={LOCATION}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.128.0.7\n"
     ]
    }
   ],
   "source": [
    "IP_ADDRESS = ! gcloud compute forwarding-rules describe op-psc-llm-endpoint --region={LOCATION} --format='value(IPAddress)'\n",
    "IP_ADDRESS = IP_ADDRESS[0]\n",
    "print(IP_ADDRESS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Request using PSC connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class CarType(str, Enum):\n",
    "    sedan = \"sedan\"\n",
    "    suv = \"SUV\"\n",
    "    truck = \"Truck\"\n",
    "    coupe = \"Coupe\"\n",
    "\n",
    "class CarDescription(BaseModel):\n",
    "    brand: str\n",
    "    model: str\n",
    "    car_type: CarType\n",
    "\n",
    "# json_schema = CarDescription.model_json_schema()\n",
    "json_schema = CarDescription.schema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt = \"Generate a JSON with the brand, model and car_type of the most iconic car of Hyundai from the 90's\"\n",
    "\n",
    "prediction_input = {\n",
    "    \"messages\": [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt,\n",
    "    }],\n",
    "    \"guided_json\": json_schema\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ \"brand\": \"Ford\", \"model\": \"Mustang GT\", \"car_type\": \"Coupe\" }\n"
     ]
    }
   ],
   "source": [
    "ENDPOINT_ID = \"7111316852524974080\"\n",
    "\n",
    "psc_endpoint = aiplatform.PrivateEndpoint(ENDPOINT_ID)\n",
    "response = psc_endpoint.raw_predict(body=json.dumps(prediction_input, indent=2).encode('utf-8'), headers={'Content-Type':'application/json'}, \n",
    "                               endpoint_override=IP_ADDRESS)\n",
    "\n",
    "print(json.loads(response.data)['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XW_BtPnEFPp4"
   },
   "source": [
    "### Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E4Ik3eKqdI_2"
   },
   "outputs": [],
   "source": [
    "psc_endpoint.undeploy_all()\n",
    "psc_endpoint.delete()\n",
    "model.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JRncavA6FSlc"
   },
   "outputs": [],
   "source": [
    "! gcloud compute forwarding-rules delete op-psc-endpoint --region={LOCATION}  --quiet\n",
    "\n",
    "! gcloud compute addresses delete psc-prediction --region={LOCATION} --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BTz-2N1XunXB"
   },
   "source": [
    "Delete the bucket if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NPQT5Wv9lC3O"
   },
   "outputs": [],
   "source": [
    "! gsutil rm -r {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2iR_Q5K_ksWi"
   },
   "source": [
    "Optionally, you can use the following command to clean up all private endpoint and models if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vkyvlwTgky0J"
   },
   "outputs": [],
   "source": [
    "for pe in aiplatform.PrivateEndpoint.list():\n",
    "    pe.undeploy_all()\n",
    "    pe.delete()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "get_started_with_psc_private_endpoint.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m127",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m127"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
