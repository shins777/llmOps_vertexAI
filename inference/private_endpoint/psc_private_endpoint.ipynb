{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UUTFwSh5u9OK"
   },
   "outputs": [],
   "source": [
    "# Copyright 2024 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qsLff0QbdE8D"
   },
   "source": [
    "# Online Prediction PSC based private endpint\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/prediction/get_started_with_psc_private_endpoint.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fvertex-ai-samples%2Fmain%2Fnotebooks%2Fofficial%2Fprediction%2Fget_started_with_psc_private_endpoint.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://cloud.google.com/ml-engine/images/colab-enterprise-logo-32px.png\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
    "    </a>\n",
    "  </td>    \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/official/prediction/get_started_with_psc_private_endpoint.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/prediction/get_started_with_psc_private_endpoint.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0C7kTlrH1bO8"
   },
   "source": [
    "## Overview\n",
    "\n",
    "Compared to the current PSA Private Endpoint, PSC based Private Endpoint has the following benefits:\n",
    "1. Simpler setup process: Currently, the only extra step user need to do is to create an Endpoint in their VPC. And this will be done by PSC automatically before our GA launch.\n",
    "\n",
    "2. No more IP exhuasted issue: GKE cluster will be hosted in tenant project VPC, so we can create much bigger cluster and won't affected by ip exhuasted issue in User's VPC.\n",
    "\n",
    "3. Unified experience with public endpoint: The API is the same as public endpoint, so user can use our SDK/client library. We also provide quota, IAM and monitoring metrics as public endpoint does.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D2sWuTr81v9m"
   },
   "source": [
    "## Get started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RakMIliNYh8O"
   },
   "source": [
    "### Install Vertex AI SDK for Python and other required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "nSHmJT9cTggu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/jupyter/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/jupyter/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/jupyter/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/jupyter/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/jupyter/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/jupyter/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip3 install --upgrade --user --quiet google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "936Zz5YI2NeA"
   },
   "source": [
    "### Restart runtime (Colab only)\n",
    "\n",
    "To use the newly installed packages, you must restart the runtime on Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "66oJ55lG2Tiq"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Clr61ben2WwY"
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>⚠️ The kernel is going to restart. Wait until it's finished before continuing to the next step. ⚠️</b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v848aGbn2acH"
   },
   "source": [
    "### Authenticate your notebook environment (Colab only)\n",
    "\n",
    "Authenticate your environment on Google Colab.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IVeoyQPz2cfh"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "\n",
    "    from google.colab import auth\n",
    "\n",
    "    auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HId-ySlY2jlI"
   },
   "source": [
    "### Set Google Cloud project information and initialize Vertex AI SDK for Python\n",
    "\n",
    "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com). Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Y4gnZI9OX6VJ"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"ai-hangsik\"  # @param {type:\"string\"}\n",
    "LOCATION = \"us-central1\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "moS794OKaaCt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://20250211_psc_endpoint/...\n",
      "ServiceException: 409 A Cloud Storage bucket named '20250211_psc_endpoint' already exists. Try another name. Bucket names must be globally unique across all Google Cloud projects, including those outside of your organization.\n"
     ]
    }
   ],
   "source": [
    "# Create GCS Bucket\n",
    "BUCKET_URI = \"gs://20250211_psc_endpoint\"  # @param {type:\"string\"}\n",
    "! gsutil mb -l {LOCATION} -p {PROJECT_ID} {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-NrpFROTjoVL"
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "swERjzZ-a_Nd"
   },
   "source": [
    "## Prepare Test Models\n",
    "\n",
    "We prepared some test models, feel free to use your own models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "3PtFCQNHbloQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://cloud-samples-data/vertex-ai/prediction/test-models-requests/churn/assets/country.txt [Content-Type=application/octet-stream]...\n",
      "Copying gs://cloud-samples-data/vertex-ai/prediction/test-models-requests/churn/assets/language.txt [Content-Type=application/octet-stream]...\n",
      "Copying gs://cloud-samples-data/vertex-ai/prediction/test-models-requests/churn/assets/operating_system.txt [Content-Type=application/octet-stream]...\n",
      "/ [3 files][  2.0 KiB/  2.0 KiB]                                                \n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m cp ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Copying gs://cloud-samples-data/vertex-ai/prediction/test-models-requests/churn/assets/user_pseudo_id.txt [Content-Type=application/octet-stream]...\n",
      "Copying gs://cloud-samples-data/vertex-ai/prediction/test-models-requests/churn/explanation_metadata.json...\n",
      "Copying gs://cloud-samples-data/vertex-ai/prediction/test-models-requests/churn/saved_model.pb...\n",
      "Copying gs://cloud-samples-data/vertex-ai/prediction/test-models-requests/churn/variables/variables.data-00000-of-00001...\n",
      "Copying gs://cloud-samples-data/vertex-ai/prediction/test-models-requests/churn/variables/variables.index...\n",
      "Copying gs://cloud-samples-data/vertex-ai/prediction/test-models-requests/pytorch/model.mar [Content-Type=application/octet-stream]...\n",
      "Copying gs://cloud-samples-data/vertex-ai/prediction/test-models-requests/requests/pytorch_request.json [Content-Type=application/json]...\n",
      "Copying gs://cloud-samples-data/vertex-ai/prediction/test-models-requests/requests/sklearn_request.json [Content-Type=application/json]...\n",
      "Copying gs://cloud-samples-data/vertex-ai/prediction/test-models-requests/requests/tensorflow_request.json [Content-Type=application/json]...\n",
      "Copying gs://cloud-samples-data/vertex-ai/prediction/test-models-requests/requests/vision_small_request.json [Content-Type=application/json]...\n",
      "Copying gs://cloud-samples-data/vertex-ai/prediction/test-models-requests/requests/xgboost_request.json [Content-Type=application/json]...\n",
      "Copying gs://cloud-samples-data/vertex-ai/prediction/test-models-requests/sklearn/model.joblib [Content-Type=application/octet-stream]...\n",
      "Copying gs://cloud-samples-data/vertex-ai/prediction/test-models-requests/tensorflow/saved_model.pb...\n",
      "Copying gs://cloud-samples-data/vertex-ai/prediction/test-models-requests/tensorflow/variables/variables.data-00000-of-00001...\n",
      "Copying gs://cloud-samples-data/vertex-ai/prediction/test-models-requests/tensorflow/variables/variables.index...\n",
      "Copying gs://cloud-samples-data/vertex-ai/prediction/test-models-requests/xgboost/model.bst [Content-Type=application/octet-stream]...\n",
      "| [19 files][  4.7 MiB/  4.7 MiB]                                               \n",
      "Operation completed over 19 objects/4.7 MiB.                                     \n"
     ]
    }
   ],
   "source": [
    "# Copy Models to the Bucket\n",
    "! gsutil cp -r \"gs://cloud-samples-data/vertex-ai/prediction/test-models-requests/*\" {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W7sbcii_iZ7x"
   },
   "source": [
    "### Upload Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "bhgBogbTgF_5"
   },
   "outputs": [],
   "source": [
    "# Depending on which model you wanna use, uncomment the corresponding section below and run the block.\n",
    "\n",
    "# TF Model\n",
    "DISPLAY_NAME = \"tensorflow model\"  # @param {type:\"string\"}\n",
    "ARTIFACT_URI = BUCKET_URI + \"/tensorflow\"\n",
    "IMAGE_URI = \"us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-12:latest\"\n",
    "REQUEST_FILE = \"tensorflow_request.json\"\n",
    "\n",
    "\n",
    "# Pytorch Model\n",
    "# DISPLAY_NAME=\"Pytorch model\"\n",
    "# ARTIFACT_URI=BUCKET_URI+\"/pytorch\"\n",
    "# IMAGE_URI=\"us-docker.pkg.dev/vertex-ai/prediction/pytorch-cpu.2-0:latest\"\n",
    "# REQUEST_FILE=\"pytorch_request.json\"\n",
    "\n",
    "\n",
    "# Sklearn Model\n",
    "# DISPLAY_NAME=\"Sklearn model\"\n",
    "# ARTIFACT_URI=BUCKET_URI+\"/sklearn\"\n",
    "# IMAGE_URI=\"us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.1-2:latest\"\n",
    "# REQUEST_FILE=\"sklearn_request.json\"\n",
    "\n",
    "\n",
    "# xgboost Model\n",
    "# DISPLAY_NAME=\"xgboost model\"\n",
    "# ARTIFACT_URI=BUCKET_URI+\"/xgboost\"\n",
    "# IMAGE_URI=\"us-docker.pkg.dev/vertex-ai/prediction/xgboost-cpu.1-7:latest\"\n",
    "# REQUEST_FILE=\"xgboost_request.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "49Dak6icicSu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model\n",
      "Create Model backing LRO: projects/721521243942/locations/us-central1/models/3752849789390159872/operations/565909735644069888\n",
      "Model created. Resource name: projects/721521243942/locations/us-central1/models/3752849789390159872@1\n",
      "To use this Model in another session:\n",
      "model = aiplatform.Model('projects/721521243942/locations/us-central1/models/3752849789390159872@1')\n"
     ]
    }
   ],
   "source": [
    "model = aiplatform.Model.upload(\n",
    "    display_name=DISPLAY_NAME,\n",
    "    artifact_uri=ARTIFACT_URI,\n",
    "    serving_container_image_uri=IMAGE_URI,\n",
    "    sync=False,\n",
    ")\n",
    "\n",
    "model.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JN2NkhEljbse"
   },
   "source": [
    "### Create PSC based Prediction Private Endpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "BqMtuRgPjqfD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PrivateEndpoint\n",
      "Create PrivateEndpoint backing LRO: projects/721521243942/locations/us-central1/endpoints/3843955322867679232/operations/561406136016699392\n",
      "PrivateEndpoint created. Resource name: projects/721521243942/locations/us-central1/endpoints/3843955322867679232\n",
      "To use this PrivateEndpoint in another session:\n",
      "endpoint = aiplatform.PrivateEndpoint('projects/721521243942/locations/us-central1/endpoints/3843955322867679232')\n"
     ]
    }
   ],
   "source": [
    "psc_endpoint = aiplatform.PrivateEndpoint.create(\n",
    "    display_name=\"psc-endpoint\",\n",
    "    project=PROJECT_ID,\n",
    "    location=LOCATION,\n",
    "    private_service_connect_config=aiplatform.PrivateEndpoint.PrivateServiceConnectConfig(\n",
    "        project_allowlist=[PROJECT_ID],\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mp-W67qKHIN6"
   },
   "source": [
    "Alternatively, send http call to create endpoint. You need to manually replace ALL the variables below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ellzpZ43jZVm"
   },
   "outputs": [],
   "source": [
    "# ! curl -X POST -H \"Content-Type: application/json\" -H \"Authorization: Bearer `gcloud auth print-access-token`\" https://${LOCATION}-aiplatform.googleapis.com/v1/projects/${PROJECT_ID}/locations/{LOCATION}/endpoints -d \\\n",
    "# '{ \\\n",
    "#     displayName: \"psc-endpoint\", \\\n",
    "#     privateServiceConnectConfig: { \\\n",
    "#       enablePrivateServiceConnect: true, \\\n",
    "#       projectAllowlist: [\"{PROJECT_ID}\"] \\\n",
    "#     }, \\\n",
    "# }'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "USWCW-SNo-9M"
   },
   "source": [
    "### Deploy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "S_eRJglhpVfL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying Model projects/721521243942/locations/us-central1/models/3752849789390159872 to PrivateEndpoint : projects/721521243942/locations/us-central1/endpoints/3843955322867679232\n",
      "Deploy PrivateEndpoint model backing LRO: projects/721521243942/locations/us-central1/endpoints/3843955322867679232/operations/3189256518587383808\n",
      "PrivateEndpoint model deployed. Resource name: projects/721521243942/locations/us-central1/endpoints/3843955322867679232\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[id: \"3250416955961638912\"\n",
       " model: \"projects/721521243942/locations/us-central1/models/3752849789390159872\"\n",
       " display_name: \"tensorflow model\"\n",
       " create_time {\n",
       "   seconds: 1739236172\n",
       "   nanos: 649325000\n",
       " }\n",
       " dedicated_resources {\n",
       "   machine_spec {\n",
       "     machine_type: \"e2-standard-8\"\n",
       "   }\n",
       "   min_replica_count: 1\n",
       "   max_replica_count: 1\n",
       " }\n",
       " private_endpoints {\n",
       "   service_attachment: \"projects/p9573c9b9f79e4e12-tp/regions/us-central1/serviceAttachments/gkedpm-d0ab76b2a55711bace1541472ae116\"\n",
       " }\n",
       " model_version_id: \"1\"\n",
       " status {\n",
       "   available_replica_count: 1\n",
       " }]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psc_endpoint.deploy(model=model, traffic_percentage=100, machine_type=\"e2-standard-8\")\n",
    "\n",
    "psc_endpoint.list_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5uLFsbxpwzvN"
   },
   "source": [
    "### Create Forwarding Rule in Consumer Project\n",
    "\n",
    "First, find the service attachment from the endpoint and deployed model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "EgjKUSAMnqvI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projects/p9573c9b9f79e4e12-tp/regions/us-central1/serviceAttachments/gkedpm-d0ab76b2a55711bace1541472ae116\n"
     ]
    }
   ],
   "source": [
    "service_attachment = psc_endpoint.list_models()[0].private_endpoints.service_attachment\n",
    "print(service_attachment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5R2z2mUlMrl9"
   },
   "source": [
    "Then, create an address and a forwarding rule targeting at the service attachment. In this example, default network and subnet are used, replace it with your VPC network and subnet if running in your VPC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did you mean region [us-central1] for address: [psc-prediction] (Y/n)?  ^C\n",
      "\n",
      "\n",
      "Command killed by keyboard interrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#! gcloud compute forwarding-rules delete  op-psc-endpoint\n",
    "#! gcloud compute addresses delete psc-prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "EF7XCp0t1_AY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created [https://www.googleapis.com/compute/v1/projects/ai-hangsik/regions/us-central1/addresses/psc-prediction].\n",
      "Created [https://www.googleapis.com/compute/v1/projects/ai-hangsik/regions/us-central1/forwardingRules/op-psc-endpoint].\n"
     ]
    }
   ],
   "source": [
    "! gcloud compute addresses create psc-prediction \\\n",
    "    --region={LOCATION} \\\n",
    "    --subnet=default2\n",
    "\n",
    "! gcloud compute forwarding-rules create op-psc-endpoint \\\n",
    "    --network=default2 \\\n",
    "    --address=psc-prediction \\\n",
    "    --target-service-attachment={service_attachment} \\\n",
    "    --region={LOCATION}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oL-74S0kVkym"
   },
   "source": [
    "Save the IP address above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "bEtkfw1dTbvh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.128.0.5\n"
     ]
    }
   ],
   "source": [
    "IP_ADDRESS = ! gcloud compute forwarding-rules describe op-psc-endpoint --region={LOCATION} --format='value(IPAddress)'\n",
    "IP_ADDRESS = IP_ADDRESS[0]\n",
    "print(IP_ADDRESS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "civyNQaPr4QD"
   },
   "source": [
    "## Make Predictions\n",
    "\n",
    "From this point, all the code below must be run from a GCP VM in the same VPC, same region as your PSC Endpoint.\n",
    "\n",
    "If you're using Vertex AI Workbench or Colab Enterprise, you should be good.\n",
    "\n",
    "If you're creating a GCE VM, please make sure Cloud Platform access scope is enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "9Y7Zr9hQuZxC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://20250211_psc_endpoint/requests/pytorch_request.json...\n",
      "Copying gs://20250211_psc_endpoint/requests/sklearn_request.json...             \n",
      "Copying gs://20250211_psc_endpoint/requests/tensorflow_request.json...          \n",
      "Copying gs://20250211_psc_endpoint/requests/vision_small_request.json...        \n",
      "- [4 files][ 16.8 KiB/ 16.8 KiB]                                                \n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m cp ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Copying gs://20250211_psc_endpoint/requests/xgboost_request.json...\n",
      "- [5 files][ 16.9 KiB/ 16.9 KiB]                                                \n",
      "Operation completed over 5 objects/16.9 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "# Download the requests files:\n",
    "! gsutil cp {BUCKET_URI}/requests/* ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "I-O9U63juoWE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction(predictions=[[-357.108429], [-171.621658]], deployed_model_id='3250416955961638912', metadata=None, model_version_id='1', model_resource_name='projects/721521243942/locations/us-central1/models/3752849789390159872', explanations=None)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    import json\n",
    "\n",
    "    import urllib3\n",
    "\n",
    "    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "    with open(REQUEST_FILE) as json_file:\n",
    "        data = json.load(json_file)\n",
    "        # print(data)\n",
    "        response = psc_endpoint.predict(\n",
    "            instances=data[\"instances\"], endpoint_override=IP_ADDRESS\n",
    "        )\n",
    "        print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U1sbaYPbueQc"
   },
   "source": [
    "### Predict Requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ngiWwtuOM1PL"
   },
   "source": [
    "Alternatively, you can send HTTP requests directly to the IP address. Make sure to replace all variabled in the requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "IjLZV-hZoNy2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/721521243942/locations/us-central1/endpoints/3843955322867679232'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ENDPOINT_RESOURCE_NAME = psc_endpoint.resource_name\n",
    "ENDPOINT_RESOURCE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "_V-Zz4N5tMev"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*   Trying 10.128.0.5:443...\n",
      "* Connected to 10.128.0.5 (10.128.0.5) port 443 (#0)\n",
      "* ALPN, offering h2\n",
      "* ALPN, offering http/1.1\n",
      "* successfully set certificate verify locations:\n",
      "*  CAfile: /etc/ssl/certs/ca-certificates.crt\n",
      "*  CApath: /etc/ssl/certs\n",
      "* TLSv1.3 (OUT), TLS handshake, Client hello (1):\n",
      "* TLSv1.3 (IN), TLS handshake, Server hello (2):\n",
      "* TLSv1.3 (OUT), TLS change cipher, Change cipher spec (1):\n",
      "* TLSv1.3 (OUT), TLS handshake, Client hello (1):\n",
      "* TLSv1.3 (IN), TLS handshake, Server hello (2):\n",
      "* TLSv1.3 (IN), TLS handshake, Encrypted Extensions (8):\n",
      "* TLSv1.3 (IN), TLS handshake, Certificate (11):\n",
      "* TLSv1.3 (IN), TLS handshake, CERT verify (15):\n",
      "* TLSv1.3 (IN), TLS handshake, Finished (20):\n",
      "* TLSv1.3 (OUT), TLS handshake, Finished (20):\n",
      "* SSL connection using TLSv1.3 / TLS_AES_256_GCM_SHA384\n",
      "* ALPN, server accepted to use h2\n",
      "* Server certificate:\n",
      "*  subject: C=US; ST=CA; L=Sunnyvale; O=Google LLC; CN=aiplatform.googleapis.com\n",
      "*  start date: Nov 20 06:20:58 2023 GMT\n",
      "*  expire date: Nov 19 06:20:58 2024 GMT\n",
      "*  issuer: C=US; ST=CA; L=Sunnyvale; O=Google LLC; CN=aiplatform.googleapis.com\n",
      "*  SSL certificate verify result: self signed certificate (18), continuing anyway.\n",
      "* Using HTTP2, server supports multi-use\n",
      "* Connection state changed (HTTP/2 confirmed)\n",
      "* Copying HTTP/2 data in stream buffer to connection buffer after upgrade: len=0\n",
      "* Using Stream ID: 1 (easy handle 0x5637cb04a640)\n",
      "> POST /v1/projects/721521243942/locations/us-central1/endpoints/3843955322867679232:rawPredict HTTP/2\n",
      "> Host: 10.128.0.5\n",
      "> user-agent: curl/7.74.0\n",
      "> accept: */*\n",
      "> content-type: application/json\n",
      "> authorization: Bearer ya29.c.c0ASRK0GaqCaDtrZMuTxKVKhauHG4D3obb24cGFHrJXyRd4rlkrgjSNmDZMVJ7H1yWdCRHJoBvJc0ldxhpU3zsV2afLYdbZazcBPPD5Q-UAJoXWHmGL7plrA6Wq4IdnnzQrId3MmVgbBQwX6OKtYYumS-jgMqne3gRqEWyN7R-0FYtLUhPIYAnf-mK0U86d5mvSCIG3qvaE07lVxn2zkvUtK26lZ-JVevFHsqpvt0WW94UJxHKM1HIUc6Cc46hlwF0ZyE3DT4oraK_k3xeBhzPOpvb1PovudwTJQ6uQJC6WtqfkPUIzHkqnV0U-Zg3lA11btw4QVTN48DVR1rvcORHWK0bqCi47PMVhr6fyYNsm9J_f_LRptffqgGbdqtfoPqgE393DhJqpfm1dgp63aJxnBXW3Ukj6rvYy976Y6yj7IsOU-hQFer47-krU8knkyYf8kvfcv0XJ3S4kyJko5F-q-pOJ35UaRfh5rIemvB8QcklVp_leX7dYdhzoeqBViaqibpi-h4iZ3807z2tWISh27yJipXBiqMmbkSgmykhcumwW5lmSZgOxIU1exqutasWbOnu7ywe5eVZhmZBJqugfgWSJsb6uQpvJIJQphmQtMl1RRc02cfBYWt4z4MSfnwfxxu74nd0ocss_O0wdW7u0oppi5yQXke6d99QMudnfbiyaiSWJ9ovsjeBnJgMtRpu3R94sxkonZp8ylOcXrMQdX94QUJoM55vVkZul68c-5RUpqlWURxxMF2UIBIiuRoMslIm6-ttR0_X1XjsW3smYmi0xnc4SUeiShm1xnppk3IBx1pju5hZMWOW40B9wg_m3VmkqqQ_ca7ByBZ_FXW0b3eeghh5wUoM-jJ2pa2_qMxUbYWuY7tok9ghZWQ1McYuMWk45hjSW7tO0cUth-dwz7uXSXI5QIIezrRrtmVc7wkeURYXMVXpiy34uMjnYvrkX9iU_anhWX_nwgaB0zbSgIp1sMQ6uQjvrvO92awMh5l0WSennUFo78e\n",
      "> content-length: 186\n",
      "> \n",
      "* We are completely uploaded and fine\n",
      "* TLSv1.3 (IN), TLS handshake, Newsession Ticket (4):\n",
      "* TLSv1.3 (IN), TLS handshake, Newsession Ticket (4):\n",
      "* old SSL session ID is stale, removing\n",
      "* Connection state changed (MAX_CONCURRENT_STREAMS == 2147483647)!\n",
      "< HTTP/2 200 \n",
      "< content-type: application/json\n",
      "< date: Tue, 11 Feb 2025 03:20:25 GMT\n",
      "< content-length: 58\n",
      "< x-vertex-ai-deployed-model-id: 3250416955961638912\n",
      "< x-vertex-ai-model: projects/721521243942/locations/us-central1/models/3752849789390159872\n",
      "< x-vertex-ai-model-display-name: tensorflow model\n",
      "< x-vertex-ai-model-version-id: 1\n",
      "< server: istio-envoy\n",
      "< x-google-netmon-label: /bns/predictor-resource-pool-1368111323325399040-db99ddfb5-mkk79/process/root/sidecar/1\n",
      "< x-google-security-signals: FRAMEWORK=HTTPSERVER2,BUILD=GOOGLE3,BUILD_DEBUG=cl:722697805\n",
      "< x-xss-protection: 0\n",
      "< x-frame-options: SAMEORIGIN\n",
      "< x-envoy-upstream-service-time: 4\n",
      "< \n",
      "{\n",
      "    \"predictions\": [[-357.108429], [-171.621658]\n",
      "    ]\n",
      "* Connection #0 to host 10.128.0.5 left intact\n",
      "}"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    # Predict\n",
    "    # ! curl --insecure -H \"Content-Type: application/json\" -H \"Authorization: Bearer `gcloud auth print-access-token`\"  https://{IP_ADDRESS}/v1/{ENDPOINT_RESOURCE_NAME}:predict -d@{REQUEST_FILE}\n",
    "\n",
    "    # # RawPredict\n",
    "    ! curl -v --insecure -H \"Content-Type: application/json\" -H \"Authorization: Bearer `gcloud auth print-access-token`\" https://{IP_ADDRESS}/v1/{ENDPOINT_RESOURCE_NAME}:rawPredict -d@{REQUEST_FILE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_TCktMxbA4mb"
   },
   "source": [
    "### Deploy another model and update traffic split\n",
    "\n",
    "Deploy another model, and update the traffic split to be 50:50, after the deployment is done, you can rerun the prediction again for multiple times, you should be able to see the deployed_model_id are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bVLgpRiRBEL7"
   },
   "outputs": [],
   "source": [
    "psc_endpoint.deploy(model=model, traffic_percentage=50, machine_type=\"e2-standard-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2dx975IkCv7v"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    import json\n",
    "\n",
    "    import urllib3\n",
    "\n",
    "    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "    counter = {}\n",
    "    with open(REQUEST_FILE) as json_file:\n",
    "        data = json.load(json_file)\n",
    "        for i in range(1000):\n",
    "            response = psc_endpoint.predict(\n",
    "                instances=data[\"instances\"], endpoint_override=IP_ADDRESS\n",
    "            )\n",
    "            if response.deployed_model_id in counter.keys():\n",
    "                counter[response.deployed_model_id] += 1\n",
    "            else:\n",
    "                counter[response.deployed_model_id] = 1\n",
    "    print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Hld7iDmEyiF"
   },
   "source": [
    "You can update the traffic split with the following command and run the code above again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HXPI-2q9Eh6X"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    deployed_model_id_0 = list(counter)[0]\n",
    "    deployed_model_id_1 = list(counter)[1]\n",
    "\n",
    "    psc_endpoint.update(\n",
    "        traffic_split={deployed_model_id_0: 20, deployed_model_id_1: 80}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XW_BtPnEFPp4"
   },
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E4Ik3eKqdI_2"
   },
   "outputs": [],
   "source": [
    "psc_endpoint.undeploy_all()\n",
    "psc_endpoint.delete()\n",
    "model.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JRncavA6FSlc"
   },
   "outputs": [],
   "source": [
    "! gcloud compute forwarding-rules delete op-psc-endpoint --region={LOCATION}  --quiet\n",
    "\n",
    "! gcloud compute addresses delete psc-prediction --region={LOCATION} --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BTz-2N1XunXB"
   },
   "source": [
    "Delete the bucket if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NPQT5Wv9lC3O"
   },
   "outputs": [],
   "source": [
    "! gsutil rm -r {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2iR_Q5K_ksWi"
   },
   "source": [
    "Optionally, you can use the following command to clean up all private endpoint and models if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vkyvlwTgky0J"
   },
   "outputs": [],
   "source": [
    "for pe in aiplatform.PrivateEndpoint.list():\n",
    "    pe.undeploy_all()\n",
    "    pe.delete()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "get_started_with_psc_private_endpoint.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m127",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m127"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
