{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056cdc65-8d5b-4087-90a8-9eb39b8ea65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2024 Forusone\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96b11eb-26e2-490e-9d4b-bb295c4708a8",
   "metadata": {},
   "source": [
    "## Custom container deploy using LocalModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf89de7a-b5ce-4e62-8934-3ce1c01b46a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/llmOps_vertexAI/llm_serving/vllm/custom\n"
     ]
    }
   ],
   "source": [
    "%cd /home/jupyter/llmOps_vertexAI/llm_serving/vllm/custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c66e6e8-b6d8-4f89-8cee-80a82eb1c092",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade --user --quiet google-cloud-aiplatform[prediction]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4a0df5-00f7-4714-97df-2919c5a7ed9a",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "417ea439-3f39-4743-b0e9-fd521415c5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "PROJECT_ID = \"ai-hangsik\"\n",
    "REGION = \"us-central1\"\n",
    "PROJECT_NUMBER = \"721521243942\"\n",
    "MODEL_PATH = \"gs://20250131_custom_handler/meta-llama/Llama-3.1-8B-Instruct\"\n",
    "MODEL_ID = \"vLLM-Meta-Llama-3.1-8B-Instruct\" # @param {type:\"string\"}\n",
    "\n",
    "MODEL_BUCKET_URI =\"gs://sllm_0106/llama3.1_8b_inst\" # @param {type:\"string\"}\n",
    "MODEL_DISPLAY_NAME = f\"{MODEL_ID}-{now}\"\n",
    "ENDPOINT_DISPLAY_NAME = f\"{MODEL_ID}-endpoint\" # @param {type:\"string\"}\n",
    "CONTAINER = \"us-docker.pkg.dev/deeplearning-platform-release/vertex-model-garden/vllm-inference.cu121.0-5.ubuntu2204.py310\"\n",
    "\n",
    "VPC_NETWORK = \"default2\" #vpc network name to peering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a71e31-061e-4ac9-ad61-1220b170fa10",
   "metadata": {},
   "source": [
    "## Local Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022fabb7-295d-485e-b311-e044190664da",
   "metadata": {},
   "source": [
    "### Build LocalModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a1e9c9ae-fa28-4856-b502-a70569a4c633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using this default Service Account: 721521243942-compute@developer.gserviceaccount.com\n"
     ]
    }
   ],
   "source": [
    "# @title Gets the default SERVICE_ACCOUNT.\n",
    "shell_output = ! gcloud projects describe $PROJECT_ID\n",
    "project_number = shell_output[-1].split(\":\")[1].strip().replace(\"'\", \"\")\n",
    "SERVICE_ACCOUNT = f\"{project_number}-compute@developer.gserviceaccount.com\"\n",
    "print(\"Using this default Service Account:\", SERVICE_ACCOUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0e9cd4b-906a-46d3-a3c7-07d10ca60946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Set accelerator.\n",
    "# Find Vertex AI prediction supported accelerators and regions [here](https://cloud.google.com/vertex-ai/docs/predictions/configure-compute).\n",
    "MACHINE_TYPE = \"g2-standard-12\" # @param {type:\"string\"}\n",
    "ACCELERATOR_TYPE = \"NVIDIA_L4\" # @param {type:\"string\"}\n",
    "ACCELERATOR_COUNT = 1 # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70868694-e6e5-453a-bcf2-99e5a5e226dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "# See https://docs.vllm.ai/en/latest/serving/engine_args.html for a list of possible arguments with descriptions.\n",
    "vllm_args = [\n",
    "    \"python\",\n",
    "    \"-m\",\n",
    "    \"vllm.entrypoints.api_server\",\n",
    "    \"--host=0.0.0.0\",\n",
    "    \"--port=8080\",\n",
    "    f\"--model={MODEL_ID}\",\n",
    "    f\"--tensor-parallel-size={ACCELERATOR_COUNT}\",\n",
    "    \"--swap-space=16\",\n",
    "    f\"--gpu-memory-utilization=0.95\",\n",
    "    f\"--max-model-len=8192\",\n",
    "    f\"--dtype=auto\",\n",
    "    f\"--max-loras=1\",\n",
    "    f\"--max-cpu-loras=8\",\n",
    "    f\"--max-num-seqs=256\",\n",
    "    \"--disable-log-stats\",\n",
    "#     \"--trust-remote-code\",\n",
    "#     \"--enforce-eager\",\n",
    "#     \"--enable-lora\",\n",
    "#     \"--model-type=llama\",\n",
    " ]\n",
    "\n",
    "env_vars = {\n",
    "    \"MODEL_ID\": MODEL_ID,\n",
    "    \"DEPLOY_SOURCE\": \"notebook\",\n",
    "    \"VERTEX_CPR_MAX_WORKERS\": \"1\",\n",
    "    \"RUST_BACKTRACE\": \"full\", #for stack trace printing,\n",
    "    \"CUDA_MEMORY_FRACTION\": \"0.93\",    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "44a46f34-0ea1-4ab6-bdcb-60b146546d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#must secure sufficient space\n",
    "from google.cloud.aiplatform.prediction import LocalModel\n",
    "local_model = LocalModel(\n",
    "                        serving_container_image_uri=CONTAINER,\n",
    "                        serving_container_args=vllm_args,\n",
    "                        serving_container_ports=[8080],\n",
    "                        # serving_container_predict_route=\"/generate\",\n",
    "                        serving_container_predict_route=\"/v1/chat/completions\",\n",
    "                        serving_container_health_route=\"/metrics\",\n",
    "                        serving_container_environment_variables=env_vars,\n",
    "                        serving_container_shared_memory_size_mb=(16 * 1024),  # 16 GB\n",
    "                        serving_container_deployment_timeout=7200,\n",
    "\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "428a67b5-a957-44dc-9ba6-7677846cc6a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image_uri: \"us-docker.pkg.dev/deeplearning-platform-release/vertex-model-garden/vllm-inference.cu121.0-5.ubuntu2204.py310\"\n",
       "args: \"python\"\n",
       "args: \"-m\"\n",
       "args: \"vllm.entrypoints.api_server\"\n",
       "args: \"--host=0.0.0.0\"\n",
       "args: \"--port=8080\"\n",
       "args: \"--model=vLLM-Meta-Llama-3.1-8B-Instruct\"\n",
       "args: \"--tensor-parallel-size=1\"\n",
       "args: \"--swap-space=16\"\n",
       "args: \"--gpu-memory-utilization=0.95\"\n",
       "args: \"--max-model-len=8192\"\n",
       "args: \"--dtype=auto\"\n",
       "args: \"--max-loras=1\"\n",
       "args: \"--max-cpu-loras=8\"\n",
       "args: \"--max-num-seqs=256\"\n",
       "args: \"--disable-log-stats\"\n",
       "env {\n",
       "  name: \"MODEL_ID\"\n",
       "  value: \"vLLM-Meta-Llama-3.1-8B-Instruct\"\n",
       "}\n",
       "env {\n",
       "  name: \"DEPLOY_SOURCE\"\n",
       "  value: \"notebook\"\n",
       "}\n",
       "env {\n",
       "  name: \"VERTEX_CPR_MAX_WORKERS\"\n",
       "  value: \"1\"\n",
       "}\n",
       "env {\n",
       "  name: \"RUST_BACKTRACE\"\n",
       "  value: \"full\"\n",
       "}\n",
       "env {\n",
       "  name: \"CUDA_MEMORY_FRACTION\"\n",
       "  value: \"0.93\"\n",
       "}\n",
       "ports {\n",
       "  container_port: 8080\n",
       "}\n",
       "predict_route: \"/v1/chat/completions\"\n",
       "health_route: \"/metrics\"\n",
       "deployment_timeout {\n",
       "  seconds: 7200\n",
       "}\n",
       "shared_memory_size_mb: 16384"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_model.get_serving_container_spec()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9789cb74-43c9-4626-bcb1-121ab3c57dd2",
   "metadata": {},
   "source": [
    "### Deploy to local endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "109910c9-ff31-4b7e-a096-7d80db1d4dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "#Manual deploy and test\n",
    "local_endpoint = local_model.deploy_to_local_endpoint(\n",
    "    artifact_uri=MODEL_PATH,\n",
    "    gpu_count=-1,\n",
    "    container_ready_timeout = 600)\n",
    "\n",
    "local_endpoint.serve()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d52f202a-e2b1-4a54-b117-c872365674ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_endpoint.print_container_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e326f784-491b-4165-be69-00e80a4ee9b4",
   "metadata": {},
   "source": [
    "### Test request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "34dfe9ad-70f5-48e8-961e-117793f336c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class CarType(str, Enum):\n",
    "    sedan = \"sedan\"\n",
    "    suv = \"SUV\"\n",
    "    truck = \"Truck\"\n",
    "    coupe = \"Coupe\"\n",
    "\n",
    "class CarDescription(BaseModel):\n",
    "    brand: str\n",
    "    model: str\n",
    "    car_type: CarType\n",
    "\n",
    "json_schema = CarDescription.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cdf96a7c-939d-42ac-b66e-dbdcab9e78c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt = \"Generate a JSON with the brand, model and car_type of the most iconic car of Hyundai from the 90's\"\n",
    "\n",
    "prediction_input = {\n",
    "    \"messages\": [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt,\n",
    "    }],\n",
    "    \"guided_json\": json_schema\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "709adb2e-87f8-4b48-9181-3cd97d3fc3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ \"brand\": \"Hyundai\", \"model\": \"Elantra\", \"car_type\": \"SUV\" }\n"
     ]
    }
   ],
   "source": [
    "response = local_endpoint.predict(request=json.dumps(prediction_input, indent=2).encode('utf-8'), headers={'Content-Type':'application/json'})\n",
    "print(response.json()[\"choices\"][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "91ef36b0-c826-44ec-8ad3-d6fea11d2c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status : <Response [200]>\n",
      "Status : running\n"
     ]
    }
   ],
   "source": [
    "# https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.prediction.LocalEndpoint#google_cloud_aiplatform_prediction_LocalEndpoint_get_container_status\n",
    "\n",
    "print(f\"Status : {local_endpoint.run_health_check(verbose=True)}\")\n",
    "print(f\"Status : {local_endpoint.get_container_status()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8af1edb-17d8-4f05-98f6-e9e5ebcdd640",
   "metadata": {},
   "source": [
    "### Stop Local Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e71db104-95f1-4a8d-a9d7-f0d5936fdfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_endpoint.stop()\n",
    "local_endpoint.print_container_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3f17c8-7394-4dc1-8c7e-f31e2949870f",
   "metadata": {},
   "source": [
    "## Model Upload to Vertex AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cfdbf5-1c47-40a6-b131-9390a6316e9c",
   "metadata": {},
   "source": [
    "### Container push to registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5939e1fa-5109-48ea-adb3-e9e8f9d3c54b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !gcloud auth configure-docker us-central1-docker.pkg.dev --quiet\n",
    "# local_model.push_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0a8720-7ca7-41aa-a2b0-d1ee2cadca47",
   "metadata": {},
   "source": [
    "### Upload model to Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9976fcf4-3211-4e57-91be-bcc02e3c5c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "model = aiplatform.Model.upload(\n",
    "    display_name = MODEL_ID,\n",
    "    local_model = local_model,\n",
    "    artifact_uri = MODEL_PATH,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1c18b5-1699-4f56-be1b-aa472a5947c4",
   "metadata": {},
   "source": [
    "## Public endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7cd43c-46d3-41c8-ac27-70d8b5d81b90",
   "metadata": {},
   "source": [
    "### Public endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8ed1fb0e-5333-407a-bae2-79422c4341d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Public and dedicated endpoint\n",
    "from google.cloud import aiplatform\n",
    "endpoint = aiplatform.Endpoint.create(\n",
    "    display_name=f\"{MODEL_ID} proxy public test endpoint\",\n",
    "    labels={\"sample-key\": \"sample-value\"},\n",
    "    #dedicated_endpoint_enabled=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6e97c4-05ad-4aad-b320-2c321cb0e0c5",
   "metadata": {},
   "source": [
    "### Model deploy on Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9734b9-617e-471d-907a-4ff24d5ddc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint.deploy(\n",
    "    model = model,\n",
    "    machine_type=\"g2-standard-24\",\n",
    "    accelerator_type=\"NVIDIA_L4\",\n",
    "    # machine_type=\"a2-highgpu-1g\",\n",
    "    # accelerator_type=\"NVIDIA_TESLA_A100\",\n",
    "    accelerator_count=2,\n",
    "    min_replica_count=1,\n",
    "    max_replica_count=1,\n",
    "    service_account=SERVICE_ACCOUNT\n",
    "    #traffic_percentage=50\n",
    "    #traffic_split={'a':50, 'b':50}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bfbeb7-cb22-44c1-99a5-0a6ce4c4b125",
   "metadata": {},
   "source": [
    "### Test to public dedicated endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d41cc7cc-1073-4ed1-81be-8b5f80f9c2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ \"brand\": \"Hyundai\", \"model\": \"Elantra\", \"car_type\": \"SUV\" }\n"
     ]
    }
   ],
   "source": [
    "#Public and dedicated endpoint predict\n",
    "from google.cloud import aiplatform\n",
    "ENDPOINT_ID = \"2161931230788976640\"\n",
    "endpoint = aiplatform.Endpoint(ENDPOINT_ID)\n",
    "response = endpoint.raw_predict(body=json.dumps(prediction_input, indent=2).encode('utf-8'), headers={'Content-Type':'application/json'})\n",
    "print(response.json()[\"choices\"][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "beafb408-936e-40a2-8299-8a4f9cf5e716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"projects/721521243942/locations/us-central1/endpoints/8123993449985736704\",\n",
      "  \"displayName\": \"Llama-3.1-8B-Instruct-TGI proxy private test endpoint2\",\n",
      "  \"deployedModels\": [\n",
      "    {\n",
      "      \"id\": \"8284245070710833152\",\n",
      "      \"model\": \"projects/721521243942/locations/us-central1/models/8490284753663033344\",\n",
      "      \"displayName\": \"Llama-3.1-8B-Instruct-TGI\",\n",
      "      \"createTime\": \"2025-02-01T23:57:27.258150Z\",\n",
      "      \"dedicatedResources\": {\n",
      "        \"machineSpec\": {\n",
      "          \"machineType\": \"a2-highgpu-1g\",\n",
      "          \"acceleratorType\": \"NVIDIA_TESLA_A100\",\n",
      "          \"acceleratorCount\": 1\n",
      "        },\n",
      "        \"minReplicaCount\": 1,\n",
      "        \"maxReplicaCount\": 1\n",
      "      },\n",
      "      \"privateEndpoints\": {\n",
      "        \"predictHttpUri\": \"http://8123993449985736704.aiplatform.googleapis.com/v1/models/8284245070710833152:predict\",\n",
      "        \"healthHttpUri\": \"http://8123993449985736704.aiplatform.googleapis.com/v1/models/8284245070710833152\"\n",
      "      },\n",
      "      \"modelVersionId\": \"1\"\n",
      "    }\n",
      "  ],\n",
      "  \"etag\": \"AMEw9yOSPOUMuS5lou6FfGM3iOikOOudFSRVspTiObY5-xR2DvXeRcStWTnqlOUlI93-\",\n",
      "  \"labels\": {\n",
      "    \"sample-key\": \"sample-value\"\n",
      "  },\n",
      "  \"createTime\": \"2025-02-01T23:57:10.480Z\",\n",
      "  \"updateTime\": \"2025-02-01T23:57:11.512692Z\",\n",
      "  \"network\": \"projects/721521243942/global/networks/default2\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Public endpoint health\n",
    "import google.auth\n",
    "import requests\n",
    "creds, project = google.auth.default()\n",
    "auth_req = google.auth.transport.requests.Request()\n",
    "creds.refresh(auth_req)\n",
    "\n",
    "PROJECT_NUMBER = \"721521243942\"\n",
    "ENDPOINT_ID = \"8123993449985736704\"\n",
    "\n",
    "url = f\"https://us-central1-aiplatform.googleapis.com/v1/projects/{PROJECT_NUMBER}/locations/us-central1/endpoints/{ENDPOINT_ID}\"\n",
    "\n",
    "headers = {'Authorization': f'Bearer {creds.token}'}\n",
    "response = requests.get(url, headers=headers)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d0d0cf-6581-4432-b91e-4ba3999629e6",
   "metadata": {},
   "source": [
    "## Private endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3fa980-4a23-4cdd-91c5-808e5b00a083",
   "metadata": {},
   "source": [
    "### Create private endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "96050e22-9c69-4deb-ab7c-6e62e2a1b43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ID=\"ai-hangsik\"\n",
    "!gcloud config set project $PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "101d043d-07b0-45b7-8447-c568c84c0797",
   "metadata": {},
   "outputs": [],
   "source": [
    "PEERING_RANGE_NAME=\"google-reserved-range2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ffaf0c-b045-45aa-940a-fb58ed880908",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud compute addresses create $PEERING_RANGE_NAME \\\n",
    "  --global \\\n",
    "  --prefix-length=16 \\\n",
    "  --description=\"peering range for Google service\" \\\n",
    "  --network=$VPC_NETWORK \\\n",
    "  --purpose=VPC_PEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8d63e94b-8063-443e-939b-257a356c87bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation \"operations/pssn.p24-721521243942-05dd38b9-5c9c-4d57-a15c-8fb64733cb67\" finished successfully.\n"
     ]
    }
   ],
   "source": [
    "!gcloud services vpc-peerings connect \\\n",
    "  --service=servicenetworking.googleapis.com \\\n",
    "  --network=$VPC_NETWORK \\\n",
    "  --ranges=$PEERING_RANGE_NAME \\\n",
    "  --project=$PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "45e6857f-0354-4d8f-8aee-a778ff2f8e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Private endpoint\n",
    "#Refer https://cloud.google.com/vertex-ai/docs/predictions/using-private-endpoints\n",
    "from google.cloud import aiplatform\n",
    "endpoint = aiplatform.PrivateEndpoint.create(\n",
    "    display_name=f\"{MODEL_ID} proxy private test endpoint2\",\n",
    "    network=f\"projects/{PROJECT_NUMBER}/global/networks/{VPC_NETWORK}\",\n",
    "    labels={\"sample-key\": \"sample-value\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942a7feb-bd22-434e-977f-344ca2e300bc",
   "metadata": {},
   "source": [
    "### Deploy private endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a163cc3d-47be-4749-ba31-e3432087c5f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#C3, L4, TPU not allowed for private endpoint\n",
    "#Refer https://cloud.google.com/vertex-ai/docs/training/configure-compute\n",
    "endpoint.deploy(\n",
    "    model = model,\n",
    "    machine_type=\"a2-highgpu-1g\",\n",
    "    accelerator_type=\"NVIDIA_TESLA_A100\",\n",
    "    accelerator_count=1,\n",
    "    min_replica_count=1,\n",
    "    max_replica_count=1,\n",
    "    # service_account=SERVICE_ACCOUNT\n",
    "    #traffic_percentage=50\n",
    "    #traffic_split={'a':50, 'b':50}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ec36ab-5037-4a98-abfd-6914ce519d70",
   "metadata": {},
   "source": [
    "### Test private endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64699879-48a4-44e4-86d3-e7f532ded2b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'{\"generated_text\":\"{ \\\\\"activity\\\\\": \\\\\"bike\\\\\", \\\\\"animals\\\\\": [\\\\\"puppy\\\\\",\\\\\"cat\\\\\" ], \\\\\"animals_seen\\\\\": 3, \\\\\"location\\\\\": \\\\\"park\\\\\"}\"}'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Private endpoint with raw predict, TGI does not use instances= so use raw_predict\n",
    "from google.cloud import aiplatform\n",
    "import json\n",
    "\n",
    "ENDPOINT_ID = \"8123993449985736704\"\n",
    "endpoint = aiplatform.PrivateEndpoint(ENDPOINT_ID)\n",
    "response = endpoint.raw_predict(body=json.dumps(prediction_input, indent=2).encode('utf-8'), headers={'Content-Type':'application/json'})\n",
    "response.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b3a69093-ac48-4f69-a3f7-8b0a92eaa4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Private endpoint health\n",
    "import google.auth\n",
    "import requests\n",
    "creds, project = google.auth.default()\n",
    "auth_req = google.auth.transport.requests.Request()\n",
    "creds.refresh(auth_req)\n",
    "\n",
    "headers = {'Authorization': f'Bearer {creds.token}'}\n",
    "response = requests.get(endpoint.health_http_uri, headers=headers)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1b08f9-fd5b-40a0-ac89-5e7153504f94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m127",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m127"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
