{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ur8xi4C7S06n"
   },
   "outputs": [],
   "source": [
    "# Copyright 2024 Forusone\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "# Serving-meta-llama/Llama-3.1-8B-Instruct-vLLM-GCS-Vertex-L4\n",
    "\n",
    "* [model_garden_pytorch_llama3_1_deployment.ipynb](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_pytorch_llama3_1_deployment.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30228,
     "status": "ok",
     "timestamp": 1737533064659,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "MPfEDElgrKAE",
    "outputId": "3034e7e7-a84f-4a09-a7f6-04435a212f21"
   },
   "outputs": [],
   "source": [
    "# @title Install and upgrade Vertex AI SDK.\n",
    "! pip3 install --upgrade --quiet google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "form",
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1737533064661,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "eaqts7U9Q1-h"
   },
   "outputs": [],
   "source": [
    "# @title Define deployment constants\n",
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "PROJECT_ID=\"ai-hangsik\" # @param {type:\"string\"}\n",
    "LOCATION=\"us-central1\"  # @param {type:\"string\"}\n",
    "\n",
    "MODEL_BUCKET_URI =\"gs://sllm_0106/llama3.1_8b_inst\" # @param {type:\"string\"}\n",
    "VLLM_DOCKER_URI = \"us-docker.pkg.dev/deeplearning-platform-release/vertex-model-garden/vllm-inference.cu121.0-5.ubuntu2204.py310\" # @param {type:\"string\"}\n",
    "\n",
    "MODEL_ID = \"vLLM-Meta-Llama-3.1-8B-Instruct\" # @param {type:\"string\"}\n",
    "MODEL_DISPLAY_NAME = f\"{MODEL_ID}-{now}\"\n",
    "ENDPOINT_DISPLAY_NAME = f\"{MODEL_ID}-endpoint\" # @param {type:\"string\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35156,
     "status": "ok",
     "timestamp": 1737533103288,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "os9UHzadQ17p",
    "outputId": "b90c5fa8-3457-4efb-bb89-8e1570e1ce58",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # @title Authentication\n",
    "# !gcloud auth login\n",
    "# !gcloud auth application-default login\n",
    "# !gcloud config set project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 3850,
     "status": "ok",
     "timestamp": 1737533110016,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "rs-rG7CnDjLC"
   },
   "outputs": [],
   "source": [
    "# @title Initialize Vertex AI\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1113,
     "status": "ok",
     "timestamp": 1737533124555,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "IWdiRwKHDvcD",
    "outputId": "329a5626-e6b4-4392-d208-ae22aa6fc8f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using this default Service Account: 721521243942-compute@developer.gserviceaccount.com\n"
     ]
    }
   ],
   "source": [
    "# @title Gets the default SERVICE_ACCOUNT.\n",
    "shell_output = ! gcloud projects describe $PROJECT_ID\n",
    "project_number = shell_output[-1].split(\":\")[1].strip().replace(\"'\", \"\")\n",
    "SERVICE_ACCOUNT = f\"{project_number}-compute@developer.gserviceaccount.com\"\n",
    "print(\"Using this default Service Account:\", SERVICE_ACCOUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1737533127924,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "Bd43MP3oHh66"
   },
   "outputs": [],
   "source": [
    "# @title Set accelerator.\n",
    "# Find Vertex AI prediction supported accelerators and regions [here](https://cloud.google.com/vertex-ai/docs/predictions/configure-compute).\n",
    "MACHINE_TYPE = \"g2-standard-12\" # @param {type:\"string\"}\n",
    "ACCELERATOR_TYPE = \"NVIDIA_L4\" # @param {type:\"string\"}\n",
    "ACCELERATOR_COUNT = 1 # @param {type:\"string\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1737533143108,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "fD6oDx5wHtpJ"
   },
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "# See https://docs.vllm.ai/en/latest/serving/engine_args.html for a list of possible arguments with descriptions.\n",
    "vllm_args = [\n",
    "    \"python\",\n",
    "    \"-m\",\n",
    "    \"vllm.entrypoints.api_server\",\n",
    "    \"--host=0.0.0.0\",\n",
    "    \"--port=8080\",\n",
    "    f\"--model={MODEL_ID}\",\n",
    "    f\"--tensor-parallel-size={ACCELERATOR_COUNT}\",\n",
    "    \"--swap-space=16\",\n",
    "    f\"--gpu-memory-utilization=0.95\",\n",
    "    f\"--max-model-len=8192\",\n",
    "    f\"--dtype=auto\",\n",
    "    f\"--max-loras=1\",\n",
    "    f\"--max-cpu-loras=8\",\n",
    "    f\"--max-num-seqs=256\",\n",
    "    \"--disable-log-stats\",\n",
    "#     \"--trust-remote-code\",\n",
    "#     \"--enforce-eager\",\n",
    "#     \"--enable-lora\",\n",
    "#     \"--model-type=llama\",\n",
    " ]\n",
    "\n",
    "env_vars = {\n",
    "    \"MODEL_ID\": MODEL_ID,\n",
    "    \"DEPLOY_SOURCE\": \"notebook\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 156865,
     "status": "ok",
     "timestamp": 1737533309656,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "KkO-fheRJNId",
    "outputId": "d39fb8ed-b923-405b-fc65-e10b3dea445d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model\n",
      "Create Model backing LRO: projects/721521243942/locations/us-central1/models/8976884619651579904/operations/8884517843257786368\n",
      "Model created. Resource name: projects/721521243942/locations/us-central1/models/8976884619651579904@1\n",
      "To use this Model in another session:\n",
      "model = aiplatform.Model('projects/721521243942/locations/us-central1/models/8976884619651579904@1')\n",
      "Deploying vLLM-Meta-Llama-3.1-8B-Instruct-2025-02-05 09:54:47.934801 on g2-standard-12 with 1 NVIDIA_L4 GPU(s).\n"
     ]
    }
   ],
   "source": [
    "model = aiplatform.Model.upload(\n",
    "    display_name=MODEL_DISPLAY_NAME,\n",
    "    artifact_uri=MODEL_BUCKET_URI,\n",
    "    serving_container_image_uri=VLLM_DOCKER_URI,\n",
    "    serving_container_args=vllm_args,\n",
    "    serving_container_ports=[8080],\n",
    "    # serving_container_predict_route=\"/generate\",\n",
    "    serving_container_predict_route=\"/v1/chat/completions\",\n",
    "    serving_container_health_route=\"/ping\",\n",
    "    serving_container_environment_variables=env_vars,\n",
    "    serving_container_shared_memory_size_mb=(16 * 1024),  # 16 GB\n",
    "    serving_container_deployment_timeout=7200,\n",
    ")\n",
    "print(\n",
    "    f\"Deploying {MODEL_DISPLAY_NAME} on {MACHINE_TYPE} with {ACCELERATOR_COUNT} {ACCELERATOR_TYPE} GPU(s).\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3292,
     "status": "ok",
     "timestamp": 1737533312946,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "bVuIGo5OysPX",
    "outputId": "8f9a9fa1-6553-40c4-a13b-cbb4267ac1f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Endpoint\n",
      "Create Endpoint backing LRO: projects/721521243942/locations/us-central1/endpoints/7096328310015131648/operations/5370478680885690368\n",
      "Endpoint created. Resource name: projects/721521243942/locations/us-central1/endpoints/7096328310015131648\n",
      "To use this Endpoint in another session:\n",
      "endpoint = aiplatform.Endpoint('projects/721521243942/locations/us-central1/endpoints/7096328310015131648')\n"
     ]
    }
   ],
   "source": [
    "endpoint = aiplatform.Endpoint.create(\n",
    "        display_name = ENDPOINT_DISPLAY_NAME,\n",
    "        dedicated_endpoint_enabled=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 642118,
     "status": "ok",
     "timestamp": 1737533955067,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "t6N3OFBzJuvj",
    "outputId": "82fd3fda-ed55-4863-ec92-ddabbb032efe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying model to Endpoint : projects/721521243942/locations/us-central1/endpoints/7096328310015131648\n",
      "Deploy Endpoint model backing LRO: projects/721521243942/locations/us-central1/endpoints/7096328310015131648/operations/746407763483033600\n",
      "Endpoint model deployed. Resource name: projects/721521243942/locations/us-central1/endpoints/7096328310015131648\n",
      "endpoint_name: 7096328310015131648\n"
     ]
    }
   ],
   "source": [
    "model.deploy(\n",
    "    endpoint=endpoint,\n",
    "    machine_type=MACHINE_TYPE,\n",
    "    accelerator_type=ACCELERATOR_TYPE,\n",
    "    accelerator_count=ACCELERATOR_COUNT,\n",
    "    deploy_request_timeout=1800,\n",
    "    service_account=SERVICE_ACCOUNT,\n",
    ")\n",
    "print(\"endpoint_name:\", endpoint.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1737534044876,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "p4qvmaK2TqYP"
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def predict_vllm(prompt: str, \n",
    "                 json_schema: str,\n",
    "                 ENDPOINT_ID: str ):\n",
    "\n",
    "    prediction_input = {\n",
    "        \"messages\": [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        }],\n",
    "        \"guided_json\": json_schema\n",
    "    }\n",
    "    \n",
    "    endpoint = aiplatform.Endpoint(ENDPOINT_ID)\n",
    "    response = endpoint.raw_predict(body=json.dumps(prediction_input, indent=2).encode('utf-8'), headers={'Content-Type':'application/json'})\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class CarType(str, Enum):\n",
    "    sedan = \"sedan\"\n",
    "    suv = \"SUV\"\n",
    "    truck = \"Truck\"\n",
    "    coupe = \"Coupe\"\n",
    "\n",
    "class CarDescription(BaseModel):\n",
    "    brand: str\n",
    "    model: str\n",
    "    car_type: CarType\n",
    "\n",
    "json_schema = CarDescription.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ \"brand\": \"Hyundai\", \"model\": \"Elantra\", \"car_type\": \"SUV\" }\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "prompt = \"Generate a JSON with the brand, model and car_type of the most iconic car of Hyundai from the 90's\"\n",
    "\n",
    "ENDPOINT_ID = next((endpoint.name for endpoint in aiplatform.Endpoint.list()\n",
    "                      if endpoint.display_name == ENDPOINT_DISPLAY_NAME),\n",
    "                      None\n",
    "                  )\n",
    "# ENDPOINT_ID = \"7096328310015131648\"\n",
    "\n",
    "response = predict_vllm(prompt, json_schema, ENDPOINT_ID)\n",
    "print(response.json()[\"choices\"][0]['message']['content'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K49PSvCJGBoc"
   },
   "source": [
    "## Generate JSON Output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MF8v83ZlMakb"
   },
   "source": [
    "### Use RESTful API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2708,
     "status": "ok",
     "timestamp": 1737535535022,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "8xPE6aPyLo4Z",
    "outputId": "55b0ae75-8d4f-46db-fbc0-61442fd9ab25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"brand\": \"Ford\", \"model\": \"Mustang\", \"car_type\": \"Coupe\"}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pydantic import BaseModel\n",
    "from enum import Enum\n",
    "import google.auth\n",
    "import requests\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "creds, project = google.auth.default()\n",
    "auth_req = google.auth.transport.requests.Request()\n",
    "creds.refresh(auth_req)\n",
    "\n",
    "PROJECT_NUMBER=\"721521243942\"\n",
    "ENDPOINT_ID = \"7096328310015131648\"\n",
    "\n",
    "class CarType(str, Enum):\n",
    "    sedan = \"sedan\"\n",
    "    suv = \"SUV\"\n",
    "    truck = \"Truck\"\n",
    "    coupe = \"Coupe\"\n",
    "\n",
    "class CarDescription(BaseModel):\n",
    "    brand: str\n",
    "    model: str\n",
    "    car_type: CarType\n",
    "\n",
    "json_schema = CarDescription.model_json_schema()\n",
    "\n",
    "prediction_input = {\n",
    "    \"model\": \"vllm-llama\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Generate a JSON with the brand, model and car_type of the most iconic car from the 90's\"\n",
    "        }\n",
    "    ],\n",
    "    \"guided_json\": json_schema\n",
    "}\n",
    "\n",
    "url = f\"https://us-central1-aiplatform.googleapis.com/v1/projects/{PROJECT_NUMBER}/locations/us-central1/endpoints/{ENDPOINT_ID}/chat/completions\"\n",
    "headers = {'Authorization': f'Bearer {creds.token}'}\n",
    "response = requests.post(url, json=prediction_input, headers=headers)\n",
    "print(response.json()[\"choices\"][0]['message']['content'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OMyxvWlFMcoC"
   },
   "source": [
    "### Use Open AI SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U -q openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3361,
     "status": "ok",
     "timestamp": 1737534762556,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "LnwDU9wzFTqY",
    "outputId": "49415178-6a4a-4bc4-c8a2-66f872a13f14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ \"brand\": \"Hyundai\", \"model\": \"Elantra\", \"car_type\": \"SUV\" }\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "from enum import Enum\n",
    "import google.auth\n",
    "import requests\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "creds, project = google.auth.default()\n",
    "auth_req = google.auth.transport.requests.Request()\n",
    "creds.refresh(auth_req)\n",
    "\n",
    "PROJECT_NUMBER=\"721521243942\"\n",
    "ENDPOINT_ID = \"7096328310015131648\"\n",
    "\n",
    "client = OpenAI(base_url=f\"https://us-central1-aiplatform.googleapis.com/v1/projects/{PROJECT_NUMBER}/locations/us-central1/endpoints/{ENDPOINT_ID}\", api_key=creds.token)\n",
    "\n",
    "class CarType(str, Enum):\n",
    "    sedan = \"sedan\"\n",
    "    suv = \"SUV\"\n",
    "    truck = \"Truck\"\n",
    "    coupe = \"Coupe\"\n",
    "\n",
    "\n",
    "class CarDescription(BaseModel):\n",
    "    brand: str\n",
    "    model: str\n",
    "    car_type: CarType\n",
    "\n",
    "json_schema = CarDescription.model_json_schema()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"vllm\",\n",
    "    messages=[{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Generate a JSON with the brand, model and car_type of the most iconic car of Hyundai from the 90's\",\n",
    "    }],\n",
    "    extra_body={\"guided_json\": json_schema},\n",
    ")\n",
    "print(completion.choices[0].message.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1cJkL_AeEruKDWFoTdQx5y32wZKv9LEZT",
     "timestamp": 1736823364211
    },
    {
     "file_id": "1uOCPG6QrRLsU5wi8-_RxJ5OIjs1TRtwm",
     "timestamp": 1736821793423
    },
    {
     "file_id": "1ufUtoMIGt4zlATBWTzAjBl5NImEUBxKI",
     "timestamp": 1736613834029
    },
    {
     "file_id": "1aXaBE0WEzfwmbFW-4vi272hlh9DKW2w7",
     "timestamp": 1736415646512
    },
    {
     "file_id": "1SlaHkIfriiF9fy0rmKDDiXpK_Z60iTrs",
     "timestamp": 1735130190117
    },
    {
     "file_id": "https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/controlled-generation/intro_controlled_generation.ipynb",
     "timestamp": 1722952953319
    }
   ],
   "toc_visible": true
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m127",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m127"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
