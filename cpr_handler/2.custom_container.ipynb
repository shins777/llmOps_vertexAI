{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac78fc0e-a66e-4488-8755-36c9dd637404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2024 Forusone\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00351be8-9ac0-4b5f-bce9-44c51c42c225",
   "metadata": {},
   "source": [
    "## Build CPR Model Server and Handler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fb14b4-f327-4301-a170-df751888eb5a",
   "metadata": {},
   "source": [
    "1. Model Server\n",
    "    * HTTP server that hosts the model.\n",
    "    * Responsible for setting up routes/ports/etc.\n",
    "2. Request Handler\n",
    "    * Responsible for webserver aspects of handling a request, such as deserializing the request body, serializing the response, setting response headers, etc.\n",
    "    * In this example, we will use the default Handler, google.cloud.aiplatform.prediction.handler.PredictionHandler provided in the SDK.\n",
    "3. Predictor\n",
    "    * Responsible for the ML logic for processing a prediction request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f270ee4-df44-4c43-a437-8dcef08cfe2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/llmOps_vertexAI/cpr_handler\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d4779b-4442-4223-87c9-563c42858b34",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f14acad4-8b27-4122-9b5f-1bcd3198dcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --upgrade --quiet  google-cloud-aiplatform \\\n",
    "                                 google-cloud-storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf3990db-fa11-4b75-82df-68962232be09",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"ai-hangsik\" \n",
    "LOCATION = \"us-central1\" \n",
    "BUCKET_URI = f\"gs://sllm_0116\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dae00014-ddc5-4f44-ab73-7200631bb85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "218f216f-2fb9-4ed3-b53a-00d8229ad51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ARTIFACT_DIR = \"cpr-handler-model\"\n",
    "REPOSITORY = \"cpr-handler-prediction\"\n",
    "IMAGE = \"cpr-handler-server\"\n",
    "MODEL_DISPLAY_NAME = \"cpr-handler-model\"\n",
    "USER_SRC_DIR = \"app\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab7f78b-b398-4862-b37b-5fb87a5cd8c9",
   "metadata": {},
   "source": [
    "### CPR source code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9df3a4fc-5dc9-4808-a286-408c4724351f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app/predictor.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $USER_SRC_DIR/predictor.py\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from google.cloud.aiplatform.prediction.predictor import Predictor\n",
    "from google.cloud.aiplatform.utils import prediction_utils\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "class CprPredictor(Predictor):\n",
    "    \n",
    "    def __init__(self):\n",
    "        return\n",
    "    \n",
    "    def load(self, artifacts_uri: str):\n",
    "\n",
    "        print(\"Load start!!!\")\n",
    "        prediction_utils.download_model_artifacts(artifacts_uri)\n",
    "\n",
    "        with open(f\"model.pkl\", \"rb\") as model_f:\n",
    "            self._model = pickle.load(model_f)\n",
    "\n",
    "        self._class_names = load_iris().target_names\n",
    "\n",
    "        print(f\"Model : {self._model}\")\n",
    "    \n",
    "    def predict(self, instances):\n",
    "        \"\"\"Performs prediction.\"\"\"\n",
    "        inputs = np.asarray(instances)\n",
    "\n",
    "        print(f\"Inputs: {inputs}\")\n",
    "        outputs = self._model.predict(inputs)\n",
    "        \n",
    "        return {\"predictions\": [self._class_names[class_num] for class_num in outputs]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a2ddc26c-64f9-4eb3-b8ca-be65755ab378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app/handler.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $USER_SRC_DIR/handler.py\n",
    "\n",
    "import csv\n",
    "from io import StringIO\n",
    "import json\n",
    "from fastapi import Response\n",
    "from google.cloud.aiplatform.prediction.handler import PredictionHandler\n",
    "\n",
    "class CprHandler(PredictionHandler):\n",
    "    \"\"\"Default prediction handler for the prediction requests sent to the application.\"\"\"\n",
    "\n",
    "    async def handle(self, request):\n",
    "        \"\"\"Handles a prediction request.\"\"\"\n",
    "        request_body = await request.body()\n",
    "        \n",
    "        print(f\"request_body : {request_body}\")\n",
    "        \n",
    "        prediction_instances = self._convert_csv_to_list(request_body)\n",
    "        prediction_results = self._predictor.postprocess(\n",
    "            self._predictor.predict(self._predictor.preprocess(prediction_instances))\n",
    "        )\n",
    "        \n",
    "        print(f\"prediction_results : {prediction_results}\")\n",
    "        \n",
    "        return Response(content=json.dumps(prediction_results))\n",
    "    \n",
    "    def _convert_csv_to_list(self, data):\n",
    "        \"\"\"Converts list of string in csv format to list of float.\n",
    "        \n",
    "        Example input:\n",
    "          b\"1.1,2.2,3.3,4.4\\n2.3,3.4,4.5,5.6\\n\"\n",
    "          \n",
    "        Example output:\n",
    "            [ [1.1, 2.2, 3.3, 4.4],[2.3, 3.4, 4.5, 5.6],]\n",
    "        \"\"\"\n",
    "        res = []\n",
    "        for r in csv.reader(StringIO(data.decode(\"utf-8\")), quoting=csv.QUOTE_NONNUMERIC):\n",
    "            res.append(r)\n",
    "        print(f\"res : {res}\")\n",
    "\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "26250e32-db94-4e91-9b87-e34a3b1f909e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile $USER_SRC_DIR/requirements.txt\n",
    "numpy\n",
    "scikit-learn\n",
    "google-cloud-storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5571caf-297c-4667-80cb-4c358a0acf21",
   "metadata": {},
   "source": [
    "### Build and serve CPR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4cd450b5-59c7-4772-814a-f5ccdfae51b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/subprocess.py:955: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
      "/opt/conda/lib/python3.10/subprocess.py:961: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdout = io.open(c2pread, 'rb', bufsize)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "from google.cloud.aiplatform.prediction import LocalModel\n",
    "from app.handler import CprHandler  # Custom predictor class\n",
    "from app.predictor import CprPredictor  # Custom Handler class\n",
    "\n",
    "# https://cloud.google.com/python/docs/reference/aiplatform/1.19.1/google.cloud.aiplatform.prediction.LocalModel#google_cloud_aiplatform_prediction_LocalModel_build_cpr_model\n",
    "\n",
    "local_model = LocalModel.build_cpr_model(\n",
    "    USER_SRC_DIR,\n",
    "    f\"{LOCATION}-docker.pkg.dev/{PROJECT_ID}/{REPOSITORY}/{IMAGE}\",\n",
    "    predictor=CprPredictor,  # custom predictor class.\n",
    "    handler=CprHandler,  # custom handler class.\n",
    "    requirements_path=os.path.join(USER_SRC_DIR, \"requirements.txt\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "05902ebb-5f71-4a22-af3d-1188912cc7e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image_uri: \"us-central1-docker.pkg.dev/ai-hangsik/cpr-handler-prediction/cpr-handler-server\"\n",
       "predict_route: \"/predict\"\n",
       "health_route: \"/health\""
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_model.get_serving_container_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b1d86621-e0a6-4052-915f-ad02f97283b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# deploy_to_local_endpoint\n",
    "# https://cloud.google.com/python/docs/reference/aiplatform/1.19.1/google.cloud.aiplatform.prediction.LocalModel#google_cloud_aiplatform_prediction_LocalModel_deploy_to_local_endpoint\n",
    "\n",
    "local_endpoint = local_model.deploy_to_local_endpoint(\n",
    "        artifact_uri=f\"{BUCKET_URI}/{MODEL_ARTIFACT_DIR}\",\n",
    "        # artifact_uri = \"app/\",\n",
    "        container_ready_timeout = 600,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d938ea46-bb94-41a3-ba62-1c5659887a58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'running'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_endpoint.serve()\n",
    "local_endpoint.get_container_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "011720ce-1d57-4dba-92a0-215c14e9ad01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "health_check_response = local_endpoint.run_health_check()\n",
    "health_check_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f5be8a-8aa4-4943-89a3-d28ca383a1b7",
   "metadata": {},
   "source": [
    "  #### Test local endpoint  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1da41ca-7a82-4451-b8cb-5d5fc75ee75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FILE = \"instances.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd38386f-5e74-49fb-ae03-f3f79b7fd9bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting instances.csv\n"
     ]
    }
   ],
   "source": [
    "%%writefile $INPUT_FILE\n",
    "6.7,3.1,4.7,1.5\n",
    "4.6,3.1,1.5,0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0177ca1f-5f2e-485f-87b8-dbdc014faf72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\"predictions\": [\"virginica\", \"virginica\"]}'\n"
     ]
    }
   ],
   "source": [
    "#Run some code here to test monitor\n",
    "predict_response = local_endpoint.predict(\n",
    "    request_file=INPUT_FILE,\n",
    "    headers={\"Content-Type\": \"application/json\"},\n",
    ")\n",
    "print(predict_response.content)\n",
    "local_endpoint.print_container_logs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a0550d47-6545-450c-b13d-362fdcd40ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_endpoint.print_container_logs(show_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9408c8cd-1ae1-4e78-beec-8c811f82ce9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_endpoint.print_container_logs_if_container_is_not_running(show_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c05227a-cc10-4a71-b2df-0f6e493994dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "local_endpoint.stop()\n",
    "local_endpoint.get_container_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c98a8e-64dd-4f47-9374-26e447527109",
   "metadata": {},
   "source": [
    "### Deploy local model on Vertex AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca91b07-065f-492d-a277-441db095aaa9",
   "metadata": {},
   "source": [
    "#### Push local model to artifact repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7b465403-d929-4d18-bb99-3ecfe9f8c73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud services enable artifactregistry.googleapis.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2717eafc-5c68-4946-bdf5-aab58b03a4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create request issued for: [cpr-handler-prediction]\n",
      "Waiting for operation [projects/ai-hangsik/locations/us-central1/operations/469\n",
      "62fe3-70c5-4bdf-a4a6-cbdda0f906be] to complete...done.                         \n",
      "Created repository [cpr-handler-prediction].\n"
     ]
    }
   ],
   "source": [
    "!gcloud artifacts repositories create {REPOSITORY} \\\n",
    "    --repository-format=docker \\\n",
    "    --location=$LOCATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "65c458b0-0100-45ab-be68-679c55ab3b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mWARNING:\u001b[0m Your config file at [/home/jupyter/.docker/config.json] contains these credential helper entries:\n",
      "\n",
      "{\n",
      "  \"credHelpers\": {\n",
      "    \"gcr.io\": \"gcloud\",\n",
      "    \"us.gcr.io\": \"gcloud\",\n",
      "    \"eu.gcr.io\": \"gcloud\",\n",
      "    \"asia.gcr.io\": \"gcloud\",\n",
      "    \"staging-k8s.gcr.io\": \"gcloud\",\n",
      "    \"marketplace.gcr.io\": \"gcloud\",\n",
      "    \"us-central1-docker.pkg.dev\": \"gcloud\"\n",
      "  }\n",
      "}\n",
      "Adding credentials for: us-central1-docker.pkg.dev\n",
      "gcloud credential helpers already registered correctly.\n"
     ]
    }
   ],
   "source": [
    "!gcloud auth configure-docker {LOCATION}-docker.pkg.dev --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "55dc763f-8119-48f0-a365-9e5796510c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/subprocess.py:955: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
      "/opt/conda/lib/python3.10/subprocess.py:961: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdout = io.open(c2pread, 'rb', bufsize)\n"
     ]
    }
   ],
   "source": [
    "local_model.push_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9d5e30-3062-4f34-8da6-6e761514a366",
   "metadata": {},
   "source": [
    "#### Upload and deploy model on Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "265b297c-ff44-43b5-9220-bd9c908ba079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model\n",
      "Create Model backing LRO: projects/721521243942/locations/us-central1/models/8566845947328331776/operations/4049362683554693120\n",
      "Model created. Resource name: projects/721521243942/locations/us-central1/models/8566845947328331776@1\n",
      "To use this Model in another session:\n",
      "model = aiplatform.Model('projects/721521243942/locations/us-central1/models/8566845947328331776@1')\n"
     ]
    }
   ],
   "source": [
    "model = aiplatform.Model.upload(\n",
    "    local_model=local_model,\n",
    "    display_name=MODEL_DISPLAY_NAME,\n",
    "    artifact_uri=f\"{BUCKET_URI}/{MODEL_ARTIFACT_DIR}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e71ff8e0-e44c-40e3-bb0f-ce1e439b1a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Endpoint\n",
      "Create Endpoint backing LRO: projects/721521243942/locations/us-central1/endpoints/6570251578542915584/operations/403698785198276608\n",
      "Endpoint created. Resource name: projects/721521243942/locations/us-central1/endpoints/6570251578542915584\n",
      "To use this Endpoint in another session:\n",
      "endpoint = aiplatform.Endpoint('projects/721521243942/locations/us-central1/endpoints/6570251578542915584')\n",
      "Deploying model to Endpoint : projects/721521243942/locations/us-central1/endpoints/6570251578542915584\n",
      "Deploy Endpoint model backing LRO: projects/721521243942/locations/us-central1/endpoints/6570251578542915584/operations/6265133700220977152\n",
      "Endpoint model deployed. Resource name: projects/721521243942/locations/us-central1/endpoints/6570251578542915584\n"
     ]
    }
   ],
   "source": [
    "deployed_model = model.deploy(\n",
    "    endpoint=aiplatform.Endpoint.create(display_name=\"cpr-handler-model-endpoint\"),\n",
    "    machine_type=\"n1-standard-4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5d52e7-69d7-4ae8-81f8-3d72d2235318",
   "metadata": {},
   "source": [
    "### Test model deployed on Vertex AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7b61bf-4b48-4a77-ac81-dfa163578974",
   "metadata": {},
   "source": [
    "#### Python Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ea596a3b-c26a-4018-b809-638b0e27587a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/721521243942/locations/us-central1/endpoints/6570251578542915584'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ENDPOINT_RESOURCE_NAME = deployed_model.resource_name\n",
    "ENDPOINT_RESOURCE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a8493742-fb40-4dba-8e06-c9cf0e2d22bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data: \"{\\\"predictions\\\": [\\\"virginica\\\", \\\"virginica\\\"]}\""
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.api import httpbody_pb2\n",
    "from google.cloud import aiplatform_v1\n",
    "\n",
    "prediction_client = aiplatform_v1.PredictionServiceClient(\n",
    "    client_options={\"api_endpoint\": f\"{LOCATION}-aiplatform.googleapis.com\"}\n",
    ")\n",
    "\n",
    "with open(INPUT_FILE) as f:\n",
    "    http_body = httpbody_pb2.HttpBody(\n",
    "        data=f.read().encode(\"utf-8\"),\n",
    "        content_type=\"text/csv\",\n",
    "    )\n",
    "\n",
    "request = aiplatform_v1.RawPredictRequest(\n",
    "    endpoint=ENDPOINT_RESOURCE_NAME,\n",
    "    http_body=http_body,\n",
    ")\n",
    "\n",
    "prediction_client.raw_predict(request=request)\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9f6c15-72a3-418a-8e7e-a1a9a535f062",
   "metadata": {},
   "source": [
    "#### HTTP curl test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "07fc931b-bba0-422c-b0f4-247ba8e7a741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6570251578542915584'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ENDPOINT_ID = deployed_model.name\n",
    "ENDPOINT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ec7f5d0e-4785-4669-94e3-26578bb866b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"predictions\": [\"virginica\", \"virginica\"]}"
     ]
    }
   ],
   "source": [
    "! curl \\\n",
    "-H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "-H \"Content-Type: text/csv\" \\\n",
    "--data-binary @instances.csv \\\n",
    "https://{LOCATION}-aiplatform.googleapis.com/v1/projects/{PROJECT_ID}/locations/{LOCATION}/endpoints/{ENDPOINT_ID}:rawPredict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0451cb00-f8c5-4378-b6c2-5efea5be4334",
   "metadata": {},
   "source": [
    "#### gcloud CLI test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "92a15330-c428-4aeb-93ce-97c6772b0850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
      "{\"predictions\": [\"virginica\", \"virginica\"]}"
     ]
    }
   ],
   "source": [
    "!gcloud ai endpoints raw-predict $ENDPOINT_ID \\\n",
    "  --region=$LOCATION \\\n",
    "  --http-headers=Content-Type=text/csv \\\n",
    "  --request=@$INPUT_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc663d3d-a92d-4100-b20b-208c4e106513",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m127",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m127"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
